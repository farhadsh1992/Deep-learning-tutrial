{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:145px;text-align:center;border: 4px solid #B3001E;background-color:#B3001E;color:white\">\n",
    "\n",
    "<header  style=\"width:100%;height:100px;\">\n",
    "  <h1><b>Chapter 010.3</b></h1>\n",
    "    <h4>SKlearn,Machine_learning,gensim,keras.perprocessing,PCA,T_SNE</h4>\n",
    "    <h4><b> Compared Different Approach for Text Embedding </b></h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #B3001E;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;height:120px;\">\n",
    "    \n",
    "<div  style=\"width:400px;position:absolute;left: auto;border: 4px solid white;background-color:#B3001E;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#chat\" style=\"padding:5px;color:white;text-align: center;\" >\n",
    "      <h5 ><b> MultinomialNB classification </b></h5>\n",
    "      <h5 ><b> sklearn TfidfTransformer,CountVectorizer </b></h5>\n",
    "      </a>\n",
    " </div>\n",
    "    \n",
    " <div style=\"width:400px;position:absolute;left: 405px;border: 4px solid white;background-color:#B3001E;color:whitee\">\n",
    "    <header></header>\n",
    "    <a href=\"#nlp\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h5 ><b> LogisticRegression </b></h5>\n",
    "      <h5 ><b> gensim.models.doc2vec </b></h5>\n",
    "      </a>\n",
    "     \n",
    "  </div>\n",
    "    <div style=\"width:400px;position:absolute;left: 810px;border: 4px solid white;background-color:#B3001E;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#end\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h5 ><b> LogisticRegression </b></h5>\n",
    "      <h5 ><b>  text_into_sequence_of_matrix </b></h5>\n",
    "      <h5 ><b> keras.preprocessing.text </b></h5>\n",
    "      </a>\n",
    "        </div>\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "</div>\n",
    "\n",
    "<!------------------------------------------------------------------------------------------------------------------------>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;height:120px;\">\n",
    "  <div  style=\"width:400px;position:absolute;left: 0px;border: 4px solid white;background-color:#B3001E;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#data\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h4 ><b> LogisticRegression </b></h4>\n",
    "      <h4 ><b>   text_into_sequence_of_integers </b></h4>\n",
    "      <h5 ><b> keras.preprocessing.text </b></h5>\n",
    "      </a>\n",
    "    </div>\n",
    "    \n",
    " \n",
    "    \n",
    "   \n",
    "\n",
    "</div>\n",
    "\n",
    "<!------------------------------------------------------------------------------------------------------------------------>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:84px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> Compared Different Approach for Text Embedding   </b></h2></header>\n",
    "  <header><h2><b>  </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>sklean_CountVectorizer_TfidfTransformer</td>\n",
       "      <td>0.729899</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>gensim.models.Doc2Vec</td>\n",
       "      <td>0.722697</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>text_into_sequence_of_matrix</td>\n",
       "      <td>0.505233</td>\n",
       "      <td>keras.preprocessing.text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>farhad.text_into_sequence_of_integers</td>\n",
       "      <td>0.513808</td>\n",
       "      <td>keras.preprocessing.text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     machine_learning                                    model  accuracy  \\\n",
       "0       MultinomialNB  sklean_CountVectorizer_TfidfTransformer  0.729899   \n",
       "1  LogisticRegression                    gensim.models.Doc2Vec  0.722697   \n",
       "2  LogisticRegression             text_into_sequence_of_matrix  0.505233   \n",
       "3  LogisticRegression    farhad.text_into_sequence_of_integers  0.513808   \n",
       "\n",
       "                     pakage  \n",
       "0                   sklearn  \n",
       "1                    gensim  \n",
       "2  keras.preprocessing.text  \n",
       "3  keras.preprocessing.text  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:84px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> MultinomialNB classification  </b></h2></header>\n",
    "  <header><h2><b> sklearn TfidfTransformer,CountVectorizer </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_result = {\n",
    "    'machine_learning': [],\n",
    "    'model':[],\n",
    "    'accuracy':[]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['pakage'] = ['sklearn','gensim','keras.preprocessing.text','keras.preprocessing.text'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "    \n",
    "https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
    " \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('/Users/apple/Documents/Programming/python/Project/data/tweets/clean01.training.1600000.processed.noemoticon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snet_x(sent):\n",
    "    sent = sent.split()\n",
    "    new_snet = []\n",
    "    for word in sent:\n",
    "        if  len(word)>1:\n",
    "            new_snet.append(word)\n",
    "            \n",
    "    return ' '.join(new_snet)\n",
    "\n",
    "df_data = df_data.dropna().reset_index(drop=True)\n",
    "df_data['text'] = df_data['text'].apply(lambda x: re.sub('-PRON- ','',x))\n",
    "df_data['text'] = df_data['text'].apply(snet_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeln(x):\n",
    "    if x==4:\n",
    "        y=1\n",
    "    else:\n",
    "        y=x\n",
    "    return y\n",
    "df_data['label'] = df_data['label'].apply(modeln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>upset not update facebook text may cry result ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>dive many time ball manage save rest go bound</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>not behave mad not see -PRON-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>hey long time see yes rain bit bit lol fine th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  created_at                                               text  \\\n",
       "0           0  2009-04-06  upset not update facebook text may cry result ...   \n",
       "1           1  2009-04-06      dive many time ball manage save rest go bound   \n",
       "2           2  2009-04-06                    whole body feel itchy like fire   \n",
       "3           3  2009-04-06                      not behave mad not see -PRON-   \n",
       "4           6  2009-04-06  hey long time see yes rain bit bit lol fine th...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18338</th>\n",
       "      <td>19993</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>yeah work better wait end wonder time keep goo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18339</th>\n",
       "      <td>19994</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>wake school good feeling ever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>19995</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>thewdb com cool hear old walt interview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18341</th>\n",
       "      <td>19996</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>ready mojo makeover ask detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18342</th>\n",
       "      <td>19997</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>happy th birthday boo alll time tupac amaru sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  created_at  \\\n",
       "18338       19993  2009-06-16   \n",
       "18339       19994  2009-06-16   \n",
       "18340       19995  2009-06-16   \n",
       "18341       19996  2009-06-16   \n",
       "18342       19997  2009-06-16   \n",
       "\n",
       "                                                    text  label  \n",
       "18338  yeah work better wait end wonder time keep goo...      1  \n",
       "18339                      wake school good feeling ever      1  \n",
       "18340            thewdb com cool hear old walt interview      1  \n",
       "18341                     ready mojo makeover ask detail      1  \n",
       "18342  happy th birthday boo alll time tupac amaru sh...      1  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trian_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_data['text'],df_data['label'], test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m \u001b[1m\n",
      "accuracy 0.729899155083129\n",
      "CPU times: user 68.8 ms, sys: 3.91 ms, total: 72.7 ms\n",
      "Wall time: 81.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = nb.predict(x_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(tcolors.GREEN,tcolors.BOLD)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "#print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_result['machine_learning'].append('MultinomialNB')\n",
    "dic_result['model'].append('sklean_CountVectorizer_TfidfTransformer')\n",
    "dic_result['accuracy'].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1089: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<100x530 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:84px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> LogisticRegression </b></h2></header>\n",
    "  <header><h2><b> gensim.models.doc2vec </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import nltk\n",
    "from datetime import datetime\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('/Users/apple/Documents/Programming/python/Project/data/tweets/clean01.training.1600000.processed.noemoticon.csv')\n",
    "def snet_x(sent):\n",
    "    sent = sent.split()\n",
    "    new_snet = []\n",
    "    for word in sent:\n",
    "        if  len(word)>1:\n",
    "            new_snet.append(word)\n",
    "            \n",
    "    return ' '.join(new_snet)\n",
    "\n",
    "df_data = df_data.dropna().reset_index(drop=True)\n",
    "df_data['text'] = df_data['text'].apply(lambda x: re.sub('-PRON- ','',x))\n",
    "df_data['text'] = df_data['text'].apply(lambda x: re.sub('-PRON-','',x))\n",
    "df_data['text'] = df_data['text'].apply(snet_x)\n",
    "#df_data['created_at'] = pd.to_datetime(df_data_pos['created_at']).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeln(x):\n",
    "    if x==4:\n",
    "        y=1\n",
    "    else:\n",
    "        y=x\n",
    "    return y\n",
    "df_data['label'] = df_data['label'].apply(modeln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18338</th>\n",
       "      <td>19993</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>yeah work better wait end wonder time keep goo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18339</th>\n",
       "      <td>19994</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>wake school good feeling ever</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>19995</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>thewdb com cool hear old walt interview</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18341</th>\n",
       "      <td>19996</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>ready mojo makeover ask detail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18342</th>\n",
       "      <td>19997</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>happy th birthday boo alll time tupac amaru sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  created_at  \\\n",
       "18338       19993  2009-06-16   \n",
       "18339       19994  2009-06-16   \n",
       "18340       19995  2009-06-16   \n",
       "18341       19996  2009-06-16   \n",
       "18342       19997  2009-06-16   \n",
       "\n",
       "                                                    text  label  \n",
       "18338  yeah work better wait end wonder time keep goo...      1  \n",
       "18339                      wake school good feeling ever      1  \n",
       "18340            thewdb com cool hear old walt interview      1  \n",
       "18341                     ready mojo makeover ask detail      1  \n",
       "18342  happy th birthday boo alll time tupac amaru sh...      1  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18343 entries, 0 to 18342\n",
      "Data columns (total 4 columns):\n",
      "Unnamed: 0    18343 non-null int64\n",
      "created_at    18343 non-null object\n",
      "text          18343 non-null object\n",
      "label         18343 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 573.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_data['text'], df_data['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "train['text'] = x_train\n",
    "train['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['text'] = x_test\n",
    "test['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "train_tagged = train.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.label]), axis=1)\n",
    "test_tagged = test.apply(lambda r: TaggedDocument(words=tokenize_text(r['text']), tags=[r.label]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['not', 'make', 'feel', 'sparkly', 'though', 'miss', 'tan'], tags=[0])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged.values[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "import multiprocessing\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=50, negative=5, hs=0, min_count=2, sample = 0, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12840/12840 [00:00<00:00, 1057221.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Building a Vocabulary\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12840/12840 [00:00<00:00, 1343684.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=200)\n",
    "model_dbow.alpha -= 0.002\n",
    "model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Final Vector Feature for the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "from farhad.Farhadcolor import tcolors,bcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[44m \u001b[92m\n",
      "Testing accuracy 0.7226967108849718\n",
      "Testing F1 score: 0.7226439884929486\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(tcolors.BOLD,tcolors.GREEN)\n",
    "print('Testing accuracy %s'%(acc))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_result['machine_learning'].append('LogisticRegression')\n",
    "dic_result['model'].append('gensim.models.Doc2Vec')\n",
    "dic_result['accuracy'].append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b>  text_into_sequence_of_matrix </b></h2></header>\n",
    "    <h5 ><b> keras.preprocessing.text </b></h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farhad.AwesomeTextTools import text_into_sequence_of_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from farhad.Farhadcolor import tcolors,bcolors\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m found 16459 unique tokens. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result, sequence = text_into_sequence_of_matrix(df_data['text'],df_data['text'],model=\"tfidf\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequence, df_data['label'],test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, padding='post',maxlen=50)\n",
    "x_test = pad_sequences(x_test, padding='post',maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Testing accuracy 0.5052333187963367\n",
      "Testing F1 score: 0.3612657026224674\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(tcolors.GREEN,'Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_result['machine_learning'].append('LogisticRegression')\n",
    "dic_result['model'].append('text_into_sequence_of_matrix')\n",
    "dic_result['accuracy'].append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b>  text_into_sequence_of_integers </b></h2></header>\n",
    "    <h5 ><b> keras.preprocessing.text </b></h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farhad.AwesomeTextTools import text_into_sequence_of_integers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from farhad.Farhadcolor import tcolors,bcolors\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import warnings\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m found 16459 unique tokens. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result, sequence = text_into_sequence_of_integers(df_data['text'],df_data['text'],model=\"tfidf\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequence, df_data['label'],test_size=0.15)\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post',maxlen=50)\n",
    "x_test = pad_sequences(x_test, padding='post',maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[631, 37, 587, 411, 1]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Testing accuracy 0.5138081395348837\n",
      " Testing F1 score: 0.5132061163567461\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(x_train, y_train)\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(tcolors.GREEN,'Testing accuracy %s' %(acc))\n",
    "print(' Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_result['machine_learning'].append('LogisticRegression')\n",
    "dic_result['model'].append('farhad.text_into_sequence_of_integers')\n",
    "dic_result['accuracy'].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> Result </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_result = pd.DataFrame()\n",
    "df_result['machine_learning'] = dic_result['machine_learning']\n",
    "df_result['model'] = dic_result['model']\n",
    "df_result['accuracy'] = dic_result['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machine_learning</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>sklean_CountVectorizer_TfidfTransformer</td>\n",
       "      <td>0.729899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>gensim.models.Doc2Vec</td>\n",
       "      <td>0.722697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>text_into_sequence_of_matrix</td>\n",
       "      <td>0.505233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>farhad.text_into_sequence_of_integers</td>\n",
       "      <td>0.513808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     machine_learning                                    model  accuracy\n",
       "0       MultinomialNB  sklean_CountVectorizer_TfidfTransformer  0.729899\n",
       "1  LogisticRegression                    gensim.models.Doc2Vec  0.722697\n",
       "2  LogisticRegression             text_into_sequence_of_matrix  0.505233\n",
       "3  LogisticRegression    farhad.text_into_sequence_of_integers  0.513808"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> PCA for text analysis </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a technique for reducing the number of dimensions in a dataset whilst retaining most information. It is using the correlation between some dimensions and tries to provide a minimum number of variables that keeps the maximum amount of variation or information about how the original data is distributed. It does not do this using guesswork but using hard mathematics and it uses something known as the eigenvalues and eigenvectors of the data-matrix. These eigenvectors of the covariance matrix have the property that they point along the major directions of variation in the data. These are the directions of maximum variation in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#B3001E;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> T-Distributed Stochastic Neighbouring Entities (t-SNE) </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sne = 10\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(df.loc[rndperm[:n_sne],feat_cols].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"layers\" style=\"width:100%;height:70px;border: 4px solid #179871;background-color:#179871;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1>+PLus Theory<h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "\n",
    "Paper: http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\n",
    " \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
