{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:125px;text-align:center;border: 4px solid #F2CA03;background-color:#F2CA03;color:black\">\n",
    "\n",
    "<header style=\"width:100%;height:140px;\">\n",
    "  <h1>Chapter 8.2</h1>\n",
    "    <h1><b>l1,l2 regularization - part 3</b></h1>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brief contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;height:100px;\">\n",
    "    \n",
    "<div  style=\"width:300px;position:absolute;left: auto;border: 4px solid white;background-color:#F2CA03;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#Forward_propagation\" style=\"padding:5px;color:black;text-align: center;\" >\n",
    "      <h4 ><b>Dropout Regularization</b></h4>\n",
    "      </a>\n",
    " </div>\n",
    "    \n",
    " <div style=\"width:300px;position:absolute;left: 305px;border: 4px solid white;background-color:#F2CA03;color:whitee\">\n",
    "    <header></header>\n",
    "    <a href=\"#Data\"style=\"position: relative;padding:5px;color:black;text-align: center;\" >\n",
    "      <h4 ><b>Data</b></h4>\n",
    "      </a>\n",
    "     \n",
    "  </div>\n",
    "    <div style=\"width:300px;position:absolute;left: 610px;border: 4px solid white;background-color:#F2CA03;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#model\"style=\"position: relative;padding:5px;color:black;text-align: center;\" >\n",
    "      <h4 ><b>model adn feed</b></h4>\n",
    "      </a>\n",
    "        </div>\n",
    "\n",
    "    \n",
    "   <div  style=\"width:300px;position:absolute;left: 915px;border: 4px solid white;background-color:#F2CA03;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#list\"style=\"position: relative;padding:5px;color:black;text-align: center;\">\n",
    "      <h4 ><b></b></h4>\n",
    "      </a>\n",
    "    </div>\n",
    "  \n",
    "    \n",
    "   <div  style=\"width:300px;position:absolute;left: 1220px;border: 4px solid white;background-color:#F2CA03;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#list\"style=\"position: relative;padding:5px;color:black;text-align: center;\" >\n",
    "      <h4 ><b></b></h4>\n",
    "      </a>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!------------------------------------------------------------------------------------------------------------------------>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"Dropout_Regularization\" style=\"width:100%;height:70px;border: 4px solid #F2CA03;background-color:#F2CA03;color:white;text-align:center;border-radius: 25px;padding:3px;color:black;\" ><h1>Dropout Regularization<h1></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "\n",
    "\n",
    "paper: https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference is that the dropout layers will periodically drop some of their neurons during training. You can use dropout layers on regular feedforward neural networks. \n",
    "\n",
    "The usual hyper-parameters for a dropout layer are the following:\n",
    "* Neuron Count\n",
    "* Activation Function\n",
    "* Dropout Probability\n",
    "\n",
    "The neuron count and activation function hyper-parameters work exactly the same way as their corresponding parameters in the dense layer type mentioned previously. The neuron count simply specifies the number of neurons in the dropout layer. The dropout probability indicates the likelihood of a neuron dropping out during the training iteration. Just as it does for a dense layer, the program specifies an activation function for the dropout layer.\n",
    "\n",
    "<img style=\"width:200px\" src=\"https://camo.githubusercontent.com/3afce3daa906c32c976682e6fb9499c979176a94/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6a656666686561746f6e2f7438315f3535385f646565705f6c6561726e696e672f6d61737465722f696d616765732f636c6173735f395f64726f706f75742e706e67\">\n",
    "\n",
    "Animation that shows how [dropout works](https://yusugomori.com/projects/deep-learning/dropout-relu) .\n",
    "\n",
    "A certain percentage of neurons will be masked during each training step. All neurons return after training is complete. To make use of dropout in Keras use the Dropout layer and specify a dropout probability. This is the percent of neurons to be dropped. Typically, this is a low value, such as 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"DATA\" style=\"width:100%;height:70px;border: 4px solid #F2CA03;background-color:#F2CA03;color:white;text-align:center;border-radius: 25px;padding:3px;color:black;\" ><h1>DATA<h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>149</td>\n",
       "      <td>4335</td>\n",
       "      <td>14.5</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>ford thunderbird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders        ...         origin              name\n",
       "232  16.0          8        ...              1  ford thunderbird\n",
       "\n",
       "[1 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/auto-mpg.csv\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from farhad_DL.utility import missing_median, to_xy\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"data/auto-mpg.csv\", na_values=[\"?\",\"NA\"])\n",
    "df.drop(\"name\",axis=1, inplace=True)\n",
    "missing_median(df,\"horsepower\")\n",
    "x, y = to_xy(df, 'mpg')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"model\" style=\"width:100%;height:70px;border: 4px solid #F2CA03;background-color:#F2CA03;color:white;text-align:center;border-radius: 25px;padding:3px;color:black;\" >\n",
    "    <h1>model and feeed<h1></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.losses import mean_squared_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.logging import set_verbosity, ERROR\n",
    "\n",
    "from tensorflow.keras import regularizers \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from farhad_DL.utils import TimeSummary, plot_training_summary, Estimate_Deeptime\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regularization():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation=\"relu\"))\n",
    "    model.add(Dropout(0.01))\n",
    "    \n",
    "    model.add(Dense(25,activation=\"relu\"))\n",
    "    model.add(Dense(10,kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01), activation=\"relu\"))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer= 'adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 49us/step\n",
      "Final score (RMSE): 2.4666355\n",
      "Final Losse: 18.628430099487304\n",
      "Final accuracy: 0.18\n"
     ]
    }
   ],
   "source": [
    "set_verbosity(ERROR)\n",
    "epochs = 1000\n",
    "monitor = EarlyStopping(monitor='val_cross',mode='auto',verbose=1,min_delta=1e-3,patience=5)\n",
    "#estimate_cpu = Estimate_Deeptime(epochs)\n",
    "time_summary = TimeSummary()\n",
    "\n",
    "model = Regularization()\n",
    "summary = model.fit(x_train,y_train, validation_data=(x_test,y_test), \n",
    "          callbacks=[monitor,time_summary], verbose=0,epochs=epochs)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "rm = np.sqrt(mean_squared_error(pred, y_test))\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(\"Final score (RMSE):\",rm)\n",
    "print(\"Final Losse:\", score[0])\n",
    "print(\"Final accuracy:\",score[1])\n",
    "#plot_training_summary(time_summary,summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
