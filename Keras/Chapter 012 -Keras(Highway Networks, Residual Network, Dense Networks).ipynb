{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:100px;text-align:center;border: 4px solid black;background-color:#4D0033;color:white\">\n",
    "\n",
    "<header style=\"width:100%;height:100px;\">\n",
    "  <h1><b> Chapter 012</b></h1>\n",
    "    <h4> Highway networks </h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #4D0033;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "(1) paper: https://arxiv.org/abs/1505.00387\n",
    "    \n",
    "(2) towardsdatascience: https://towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5        \n",
    " \n",
    "(3) Highway Networks with TensorFlow: https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa\n",
    "   \n",
    "(4) HighwayNets: https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32 \n",
    "    \n",
    "(5)    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#00404D;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "  <strong> Summary: </strong><br>\n",
    "        \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:25%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> contents-Paper:  </h4>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"A1\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> (Theory) Highway Networks, by Srivastava, 2015 </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"E1\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  What is gradient vanishing problem: </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"B1\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Residual Network </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"C1\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Highway Networks </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"D1\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Dense Networks </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:white;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"F1\" style=\"position: relative;padding:5px;color:white;text-align: center;\">   </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"A2\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> pycode </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"B2\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Load data </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"C2\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Residual Network </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"D2\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Highway Networks </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"E2\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  REF2 </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"F2\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  REF1 </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"G2\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Dense Networks  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:white;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"H2\" style=\"position: relative;padding:5px;color:white;text-align: center;\">   </a></h6>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"B\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1>  gradient vanishing problem, Highway Networks, Residual Network, Dense Networks   </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/2600/1*Z1DlaJC54ZrgIIyNijtjNQ@2x.jpeg\" style=\"height:320px;width:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"A1\" style=\"width:100%;height:50px;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h3>  Theory  </h3>\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "(1) Highway Networks paper: https://arxiv.org/abs/1505.00387\n",
    "    \n",
    "(2) towardsdatascience: https://towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5\n",
    "    \n",
    "(3) HighwayNets: https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32\n",
    "    \n",
    "(4) Residual Network paper: https://arxiv.org/abs/1603.05027    \n",
    "    \n",
    "(5) Dense Network paper:https://arxiv.org/abs/1608.06993   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"E1\" style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> What is gradient vanishing problem:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is found that there is difficulties optimizing a very deep neural network. It is probably due to gradient vanishing problem.\n",
    "Authors thereby make use of gating function to adaptively transform or bypass the signal so that the network can go deeper. It is probably due to gradient vanishing problem. For a network with more than a couple dozen layers however, the signal essentially disappears by the time it reaches the beginning of the network again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Note:**\n",
    "\n",
    "- Training deeper networks is not as straightforward as simply adding layers. Optimization of deep networks has proven to be considerably more difficult,\n",
    "- Highway model architecture is inspired by Long Short Term Memory recurrent neural networks.\n",
    "- Highway networks as deep as 900 layers can be optimized using simple Stochastic Gradient Descent (SGD) with momentum, for up to 100 layers we compare their training behavior to that of traditional networks with normalized initialization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two Models were introduced for solving the  gradient vanishing problem:\n",
    "1. Residual Network\n",
    "2. Highway Networks\n",
    "3. Dense Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"B1\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>  Residual Network </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Residual Network, or ResNet is a neural network architecture which solves the problem of vanishing gradients in the simplest way possible. <br>\n",
    "The idea of model is that provide the network with a shortcut at each layer to make things happen more smoothly.<br>\n",
    "In a traditional network the activation at a layer is defined as follows:    **[REF3]**<br>\n",
    "    \n",
    "## $ y = f(x,w_h,b) $, \n",
    "    \n",
    "Instead, at each layer the ResNet implements:    \n",
    "    \n",
    "## $ y = f(x,w_h,b)+x $,\n",
    "    \n",
    "The “+ x” at the end is the shortcut. It allows the gradient to pass backwards directly. By stacking these layers, the gradient could theoretically “skip” over all the intermediate layers and reach the bottom without being diminished.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*hx7aqbQmlspkrA7wLinFpg.png\" style=\"height:300px;border:3px solid #1E00B3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"B1\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Highway Networks  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a simple layer of dee learning is typically made from **a transform activation funcation** like $f$:\n",
    "\n",
    "## $ y = f(x,w_h,b) $, \n",
    "\n",
    "x as input  and y as output.\n",
    "for example:\n",
    "\n",
    "$y = f(x.w_h+b) (for Relu)$, \n",
    " \n",
    "But **for highway**, we additionally **define two other nonliear transform funcations**, such that:\n",
    "\n",
    "## $y = f(x,w_h,b).T(x,w_T)+x.C(x,w_C)$\n",
    "\n",
    "That $T(x,w_T)$ is as **the transform gate** and $C(x,w_C)$ is as  **the carry gate**(save Memmory gate) like forget-get in LSTM, They have the responssible that express **how much of the output is produced by transforming the input and carrying it**,<br>\n",
    "For simplicity, in this paper we set C = 1 − T , giving,\n",
    "<div style=\"border:3px solid #4D0033;width:40%;font-size:20px;padding:2%;margin:1%\">\n",
    "$y = f(x,w_h,b).T(x,w_T)+(1-T(x,w_T))$\n",
    "</div>  \n",
    "The dimensionality of $x,y,H(x,W_H) and T(x,W_T)$ must be the same for Equation above to be valid.<br>\n",
    "In particular, observe that\n",
    "\n",
    "<div style=\"border:3px solid #4D0033;width:40%;font-size:20px;padding:2%;margin:1%\">\n",
    " $y=\\begin{cases}\n",
    "    x       & \\quad \\text{if } T(x,w_T) \\text{ =0}\\\\\n",
    "    f(x,w_h,b) & \\quad \\text{if } T(x,w_T) \\text{ =1}\n",
    "  \\end{cases}$\n",
    "  \n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for the **Jacobian of the layer transform**,\n",
    "\n",
    "## $\\frac{dy}{dx}=\\begin{cases}\n",
    "    I      & \\quad \\text{if } T(x,w_T) \\text{ =0}\\\\\n",
    "    \\frac{\\partial f(x,w_h,b)}{\\partial x}  & \\quad \\text{if } T(x,w_T) \\text{ =1}\n",
    "  \\end{cases}$\n",
    "  \n",
    "Thus, depending on the output of the transform gates, a highway layer can smoothly vary its behavior between that of a plain layer and that of a layer which simply passes its inputs through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Highway Network architecture:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional highway layers are constructed similar to fully connected layers. Weight-sharing and local receptive fields are utilized for both H and T transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*qHf_AHv8yJJsKQok4KS4Jw.png\" style=\"border:3px solid #009999\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, **T(x) is the sigmoid function**:\n",
    "\n",
    "## $T(x,w_T,b_T) = \\sigma (w_T^T x+b_T)$\n",
    "\n",
    "That\n",
    "\n",
    "## $\\sigma(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "As we know, sigmoid function caps the output between 0 to 1. When the input has too small value, it becomes 0. When the input has too large value, it becomes 1. **Therefore, by learning $W_T$ and $b_T$, the network can adaptively pass $f(x)$ or just pass x to next layer.**\n",
    "\n",
    "### **Note:** \n",
    "\n",
    "- Author claims that this helps to have a simple initialization scheme for WT which is independent of the nature of H.\n",
    "- $b_T$ can be initialized with a negative value (e.g. -1, -3 etc.) such that the network is initially biased towards carry behavior.\n",
    "- Stochastic Gradient Descent (SGD) did not stall for networks with more than 1000 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> :  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"C1\"  style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Dense Networks  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is that if connecting a skip connection from the previous layer improves performance.**connecting every layer to every other layer** That way there is always a direct route for the information backwards through the network.**[REF3]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*KOjUX1ST5RnDOZWWLWRGkw.png\" style=\"height:300px;border:3px solid #009999\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically this looks like:\n",
    "    \n",
    "## $y = f(x,x_1,x_2, ... , x_n)$    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Advantegies of Dense Networks :  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Note:**\n",
    "\n",
    "In the feed-forward setting,\n",
    "-  a task may benefit from being able to get low-level feature activations in addition to high level feature activations.\n",
    "In classifying objects for example,\n",
    "- a lower layer of the network may determine edges in an image, whereas a higher layer would determine larger-scale features such as presence of faces. There may be cases where being able to use information about edges can help in determining the correct object in a complex scene\n",
    "\n",
    "In the backwards case,\n",
    "- having all the layers connected allows us to quickly send gradients to their respective places in the network easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"A2\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1>  pycode  </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "(1) Highway Networks with TensorFlow: https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa\n",
    "   \n",
    "(2) HighwayNets: https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32         \n",
    "  \n",
    "Dataset for test (CIFAR10): https://www.cs.toronto.edu/~kriz/cifar.html     \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"B2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>  Load data </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"C2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>  Residual Networks [REF2] </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resUnit(input_layer,i):\n",
    "    with tf.variable_scope(\"res_unit\"+str(i)):\n",
    "        part1 = slim.batch_norm(input_layer,activation_fn=None)\n",
    "        part2 = tf.nn.relu(part1)\n",
    "        part3 = slim.conv2d(part2,64,[3,3],activation_fn=None)\n",
    "        part4 = slim.batch_norm(part3,activation_fn=None)\n",
    "        part5 = tf.nn.relu(part4)\n",
    "        part6 = slim.conv2d(part5,64,[3,3],activation_fn=None)\n",
    "        output = input_layer + part6\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_layers = 25 #Specify how deep we want our network\n",
    "units_between_stride = total_layers / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_layer = tf.placeholder(shape=[None,32,32,3],dtype=tf.float32,name='input')\n",
    "label_layer = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "label_oh = slim.layers.one_hot_encoding(label_layer,10)\n",
    "\n",
    "layer1 = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(0))\n",
    "for i in range(5):\n",
    "    for j in range(units_between_stride):\n",
    "        layer1 = resUnit(layer1,j + (i*units_between_stride))\n",
    "    layer1 = slim.conv2d(layer1,64,[3,3],stride=[2,2],normalizer_fn=slim.batch_norm,scope='conv_s_'+str(i))\n",
    "    \n",
    "top = slim.conv2d(layer1,10,[3,3],normalizer_fn=slim.batch_norm,activation_fn=None,scope='conv_top')\n",
    "\n",
    "output = slim.layers.softmax(slim.layers.flatten(top))\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(label_oh * tf.log(output) + 1e-10, reduction_indices=[1]))\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "update = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"D2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>  Highway Networks </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"E2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>  :[REF2] </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_layers = 25 #Specify how deep we want our network\n",
    "units_between_stride = total_layers / 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highwayUnit(input_layer,i):\n",
    "    with tf.variable_scope(\"highway_unit\"+str(i)):\n",
    "        H = slim.conv2d(input_layer,64,[3,3])\n",
    "        T = slim.conv2d(input_layer,64,[3,3], #We initialize with a negative bias to push the network to use the skip connection\n",
    "            biases_initializer=tf.constant_initializer(-1.0),activation_fn=tf.nn.sigmoid)\n",
    "        output = H*T + input_layer*(1.0-T)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_layer = tf.placeholder(shape=[None,32,32,3],dtype=tf.float32,name='input')\n",
    "label_layer = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "label_oh = slim.layers.one_hot_encoding(label_layer,10)\n",
    "\n",
    "layer1 = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(0))\n",
    "for i in range(5):\n",
    "    for j in range(units_between_stride):\n",
    "        layer1 = highwayUnit(layer1,j + (i*units_between_stride))\n",
    "    layer1 = slim.conv2d(layer1,64,[3,3],stride=[2,2],normalizer_fn=slim.batch_norm,scope='conv_s_'+str(i))\n",
    "    \n",
    "top = slim.conv2d(layer1,10,[3,3],normalizer_fn=slim.batch_norm,activation_fn=None,scope='conv_top')\n",
    "\n",
    "output = slim.layers.softmax(slim.layers.flatten(top))\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(label_oh * tf.log(output) + 1e-10, reduction_indices=[1]))\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "update = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"F2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>  :[REF1] </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(x, input_size, output_size, activation):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1), name=\"weight\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_size]), name=\"bias\")\n",
    "    y = activation(tf.matmul(x, W) + b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highway(x, size, activation, carry_bias=-1.0):\n",
    "    W_T = tf.Variable(tf.truncated_normal([size, size], stddev=0.1), name=\"weight_transform\")\n",
    "    b_T = tf.Variable(tf.constant(carry_bias, shape=[size]), name=\"bias_transform\")\n",
    "\n",
    "    W = tf.Variable(tf.truncated_normal([size, size], stddev=0.1), name=\"weight\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size]), name=\"bias\")\n",
    "\n",
    "    T = tf.sigmoid(tf.matmul(x, W_T) + b_T, name=\"transform_gate\")\n",
    "    H = activation(tf.matmul(x, W) + b, name=\"activation\")\n",
    "    C = tf.sub(1.0, T, name=\"carry_gate\")\n",
    "\n",
    "    y = tf.add(tf.mul(H, T), tf.mul(x, C), \"y\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"G2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Dense Networks </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_layers = 25 #Specify how deep we want our network\n",
    "units_between_stride = total_layers / 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseBlock(input_layer,i,j):\n",
    "    with tf.variable_scope(\"dense_unit\"+str(i)):\n",
    "        nodes = []\n",
    "        a = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm)\n",
    "        nodes.append(a)\n",
    "        for z in range(j):\n",
    "            b = slim.conv2d(tf.concat(3,nodes),64,[3,3],normalizer_fn=slim.batch_norm)\n",
    "            nodes.append(b)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "input_layer = tf.placeholder(shape=[None,32,32,3],dtype=tf.float32,name='input')\n",
    "label_layer = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "label_oh = slim.layers.one_hot_encoding(label_layer,10)\n",
    "\n",
    "layer1 = slim.conv2d(input_layer,64,[3,3],normalizer_fn=slim.batch_norm,scope='conv_'+str(0))\n",
    "for i in range(5):\n",
    "    layer1 = denseBlock(layer1,i,units_between_stride)\n",
    "    layer1 = slim.conv2d(layer1,64,[3,3],stride=[2,2],normalizer_fn=slim.batch_norm,scope='conv_s_'+str(i))\n",
    "    \n",
    "top = slim.conv2d(layer1,10,[3,3],normalizer_fn=slim.batch_norm,activation_fn=None,scope='conv_top')\n",
    "\n",
    "output = slim.layers.softmax(slim.layers.flatten(top))\n",
    "\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(label_oh * tf.log(output) + 1e-10, reduction_indices=[1]))\n",
    "trainer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "update = trainer.minimize(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
