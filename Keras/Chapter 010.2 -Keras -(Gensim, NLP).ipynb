{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:125px;text-align:center;border: 4px solid #A52A2A;background-color:#A52A2A;color:white\">\n",
    "\n",
    "<header  style=\"width:100%;height:100px;\">\n",
    "  <h1><b>Chapter 010.2</b></h1>\n",
    "    <h4>Gensim, deep learning</h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #A52A2A;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brief contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"position: relative;height:100px;\">\n",
    "    \n",
    "<div  style=\"width:300px;position:absolute;left: auto;border: 4px solid white;background-color:#A52A2A;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#chat\" style=\"padding:5px;color:white;text-align: center;\" >\n",
    "      <h4 ><b> </b></h4>\n",
    "      </a>\n",
    " </div>\n",
    "    \n",
    " <div style=\"width:300px;position:absolute;left: 305px;border: 4px solid white;background-color:#A52A2A;color:whitee\">\n",
    "    <header></header>\n",
    "    <a href=\"#nlp\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h5 ><b>  </b></h5>\n",
    "      </a>\n",
    "     \n",
    "  </div>\n",
    "    <div style=\"width:300px;position:absolute;left: 610px;border: 4px solid white;background-color:#A52A2A;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#end\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h4 ><b> </b></h4>\n",
    "      </a>\n",
    "        </div>\n",
    "\n",
    "    \n",
    "   <div  style=\"width:300px;position:absolute;left: 915px;border: 4px solid white;background-color:#A52A2A;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#data\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h4 ><b> </b></h4>\n",
    "      </a>\n",
    "    </div>\n",
    "  \n",
    "    \n",
    "   <div  style=\"width:300px;position:absolute;left: 1220px;border: 4px solid white;background-color:#A52A2A;color:white\">\n",
    "    <header></header>\n",
    "    <a href=\"#building\"style=\"position: relative;padding:5px;color:white;text-align: center;\" >\n",
    "      <h4 ><b> </b></h4>\n",
    "      </a>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<!------------------------------------------------------------------------------------------------------------------------>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"chat\" style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#A52A2A;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b>  </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XHu5VS2cYWo\n",
    "\n",
    "https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "\n",
    " https://www.youtube.com/watch?v=3s6KnA42Kuc&frags=pl%2Cwn\n",
    "    \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='end' style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#A52A2A;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b>  </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='end' style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#A52A2A;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> Preprocessing </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/apple/Documents/Programming/python/Deep-learning/Keras/data/2Tesla_label_from_2010-06-29_to_2019-02-26_2019227.csv')\n",
    "df_data = pd.read_csv('/Users/apple/Documents/Programming/python/Project/data/tweets/Secound_CLean_training.1600000.processed.noemoticon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snet_x(sent):\n",
    "    sent = sent.split()\n",
    "    new_snet = []\n",
    "    for word in sent:\n",
    "        if  len(word)>1:\n",
    "            new_snet.append(word)\n",
    "            \n",
    "    return ' '.join(new_snet)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x: re.sub('-PRON- ','',x))\n",
    "df['clean_text'] = df['clean_text'].apply(snet_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Price_label(0,1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>trump tusk tesla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>tesla elon musk may trouble want hold contempt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>year people find tesla teleportation achieve y...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>look mx efficient compare audi jaguar</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-14</td>\n",
       "      <td>tesla musk risk contempt charge sec argue twee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at                                         clean_text  \\\n",
       "0  2010-06-29                                   trump tusk tesla   \n",
       "1  2010-06-29  tesla elon musk may trouble want hold contempt...   \n",
       "2  2010-07-01  year people find tesla teleportation achieve y...   \n",
       "3  2010-07-02              look mx efficient compare audi jaguar   \n",
       "4  2010-07-14  tesla musk risk contempt charge sec argue twee...   \n",
       "\n",
       "   Price_label(0,1)  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                -1  \n",
       "3                -1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2816 entries, 0 to 2815\n",
      "Data columns (total 3 columns):\n",
      "created_at          2816 non-null object\n",
      "clean_text          2816 non-null object\n",
      "Price_label(0,1)    2816 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 66.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at          0\n",
       "clean_text          0\n",
       "Price_label(0,1)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 474001 entries, 0 to 474000\n",
      "Data columns (total 4 columns):\n",
      "Unnamed: 0    474001 non-null int64\n",
      "create_at     474001 non-null object\n",
      "text          465505 non-null object\n",
      "label         474001 non-null int64\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "create_at        0\n",
       "text          8496\n",
       "label            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>create_at</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>awww   that s a bummer    -PRON- shoulda get d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>be upset that -PRON- can t update -PRON- faceb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>i dive many time for the ball   manage to save...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>-PRON- whole body feel itchy and like -PRON- o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>no   -PRON- s not behave at all   i m mad   wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     create_at  \\\n",
       "0           0  Mon Apr 06 22:19:45 PDT 2009   \n",
       "1           1  Mon Apr 06 22:19:49 PDT 2009   \n",
       "2           2  Mon Apr 06 22:19:53 PDT 2009   \n",
       "3           3  Mon Apr 06 22:19:57 PDT 2009   \n",
       "4           4  Mon Apr 06 22:19:57 PDT 2009   \n",
       "\n",
       "                                                text  label  \n",
       "0  awww   that s a bummer    -PRON- shoulda get d...      0  \n",
       "1  be upset that -PRON- can t update -PRON- faceb...      0  \n",
       "2  i dive many time for the ball   manage to save...      0  \n",
       "3  -PRON- whole body feel itchy and like -PRON- o...      0  \n",
       "4  no   -PRON- s not behave at all   i m mad   wh...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snet_x(sent):\n",
    "    sent = sent.split()\n",
    "    new_snet = []\n",
    "    for word in sent:\n",
    "        if  len(word)>1:\n",
    "            new_snet.append(word)\n",
    "            \n",
    "    return ' '.join(new_snet)\n",
    "\n",
    "df_data = df_data.dropna().reset_index(drop=True)\n",
    "df_data['text'] = df_data['text'].apply(lambda x: re.sub('-PRON- ','',x))\n",
    "df_data['text'] = df_data['text'].apply(snet_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>create_at</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>awww that bummer shoulda get david carr of thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>be upset that can update facebook by text and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>dive many time for the ball manage to save the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>whole body feel itchy and like on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>no not behave at all mad why be here because c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     create_at  \\\n",
       "0           0  Mon Apr 06 22:19:45 PDT 2009   \n",
       "1           1  Mon Apr 06 22:19:49 PDT 2009   \n",
       "2           2  Mon Apr 06 22:19:53 PDT 2009   \n",
       "3           3  Mon Apr 06 22:19:57 PDT 2009   \n",
       "4           4  Mon Apr 06 22:19:57 PDT 2009   \n",
       "\n",
       "                                                text  label  \n",
       "0  awww that bummer shoulda get david carr of thi...      0  \n",
       "1  be upset that can update facebook by text and ...      0  \n",
       "2  dive many time for the ball manage to save the...      0  \n",
       "3             whole body feel itchy and like on fire      0  \n",
       "4  no not behave at all mad why be here because c...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "create_at     0\n",
      "text          0\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='end' style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#A52A2A;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> Bigrams </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "https://radimrehurek.com/gensim/models/phrases.html    \n",
    "    \n",
    "    \n",
    "https://www.pydoc.io/pypi/gensim-3.2.0/autoapi/models/word2vec/index.html\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:41:26: collecting all words and their counts\n",
      "INFO - 14:41:26: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 14:41:26: collected 18220 word types from a corpus of 27580 words (unigram + bigrams) and 2816 sentences\n",
      "INFO - 14:41:26: using 18220 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sents = [x.split() for x in df['clean_text']]\n",
    "phrases = Phrases(sents, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:42:48: source_vocab length 18220\n",
      "INFO - 14:42:48: Phraser built with 43 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:43:01: collecting all words and their counts\n",
      "INFO - 14:43:01: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 14:43:02: PROGRESS: at sentence #10000, processed 114484 words and 68885 word types\n",
      "INFO - 14:43:02: PROGRESS: at sentence #20000, processed 226968 words and 117708 word types\n",
      "INFO - 14:43:02: PROGRESS: at sentence #30000, processed 340431 words and 160429 word types\n",
      "INFO - 14:43:02: PROGRESS: at sentence #40000, processed 455472 words and 200465 word types\n",
      "INFO - 14:43:03: PROGRESS: at sentence #50000, processed 570773 words and 239665 word types\n",
      "INFO - 14:43:03: PROGRESS: at sentence #60000, processed 684047 words and 276129 word types\n",
      "INFO - 14:43:03: PROGRESS: at sentence #70000, processed 796622 words and 309208 word types\n",
      "INFO - 14:43:03: PROGRESS: at sentence #80000, processed 909399 words and 341761 word types\n",
      "INFO - 14:43:04: PROGRESS: at sentence #90000, processed 1024697 words and 374369 word types\n",
      "INFO - 14:43:04: PROGRESS: at sentence #100000, processed 1139872 words and 406507 word types\n",
      "INFO - 14:43:04: PROGRESS: at sentence #110000, processed 1253367 words and 437129 word types\n",
      "INFO - 14:43:05: PROGRESS: at sentence #120000, processed 1366173 words and 466620 word types\n",
      "INFO - 14:43:05: PROGRESS: at sentence #130000, processed 1480678 words and 495869 word types\n",
      "INFO - 14:43:05: PROGRESS: at sentence #140000, processed 1596779 words and 525543 word types\n",
      "INFO - 14:43:05: PROGRESS: at sentence #150000, processed 1712855 words and 554661 word types\n",
      "INFO - 14:43:06: PROGRESS: at sentence #160000, processed 1826111 words and 582205 word types\n",
      "INFO - 14:43:06: PROGRESS: at sentence #170000, processed 1941308 words and 610198 word types\n",
      "INFO - 14:43:06: PROGRESS: at sentence #180000, processed 2053224 words and 636115 word types\n",
      "INFO - 14:43:06: PROGRESS: at sentence #190000, processed 2165407 words and 661347 word types\n",
      "INFO - 14:43:07: PROGRESS: at sentence #200000, processed 2281012 words and 687767 word types\n",
      "INFO - 14:43:07: PROGRESS: at sentence #210000, processed 2394126 words and 713760 word types\n",
      "INFO - 14:43:07: PROGRESS: at sentence #220000, processed 2504805 words and 738445 word types\n",
      "INFO - 14:43:07: PROGRESS: at sentence #230000, processed 2617360 words and 762934 word types\n",
      "INFO - 14:43:08: PROGRESS: at sentence #240000, processed 2732586 words and 787796 word types\n",
      "INFO - 14:43:08: PROGRESS: at sentence #250000, processed 2844633 words and 810856 word types\n",
      "INFO - 14:43:08: PROGRESS: at sentence #260000, processed 2956833 words and 833502 word types\n",
      "INFO - 14:43:08: PROGRESS: at sentence #270000, processed 3072745 words and 857323 word types\n",
      "INFO - 14:43:09: PROGRESS: at sentence #280000, processed 3187270 words and 880515 word types\n",
      "INFO - 14:43:09: PROGRESS: at sentence #290000, processed 3300239 words and 903474 word types\n",
      "INFO - 14:43:09: PROGRESS: at sentence #300000, processed 3412239 words and 925441 word types\n",
      "INFO - 14:43:10: PROGRESS: at sentence #310000, processed 3527145 words and 948003 word types\n",
      "INFO - 14:43:10: PROGRESS: at sentence #320000, processed 3642059 words and 971023 word types\n",
      "INFO - 14:43:10: PROGRESS: at sentence #330000, processed 3754201 words and 992787 word types\n",
      "INFO - 14:43:11: PROGRESS: at sentence #340000, processed 3870037 words and 1016064 word types\n",
      "INFO - 14:43:11: PROGRESS: at sentence #350000, processed 3983829 words and 1038037 word types\n",
      "INFO - 14:43:11: PROGRESS: at sentence #360000, processed 4097212 words and 1060095 word types\n",
      "INFO - 14:43:11: PROGRESS: at sentence #370000, processed 4207844 words and 1080874 word types\n",
      "INFO - 14:43:12: PROGRESS: at sentence #380000, processed 4322348 words and 1103151 word types\n",
      "INFO - 14:43:12: PROGRESS: at sentence #390000, processed 4435595 words and 1124235 word types\n",
      "INFO - 14:43:12: PROGRESS: at sentence #400000, processed 4548007 words and 1145054 word types\n",
      "INFO - 14:43:12: PROGRESS: at sentence #410000, processed 4658366 words and 1165648 word types\n",
      "INFO - 14:43:13: PROGRESS: at sentence #420000, processed 4771558 words and 1186877 word types\n",
      "INFO - 14:43:13: PROGRESS: at sentence #430000, processed 4883926 words and 1207745 word types\n",
      "INFO - 14:43:13: PROGRESS: at sentence #440000, processed 4995456 words and 1227812 word types\n",
      "INFO - 14:43:13: PROGRESS: at sentence #450000, processed 5107130 words and 1247603 word types\n",
      "INFO - 14:43:14: PROGRESS: at sentence #460000, processed 5220308 words and 1268348 word types\n",
      "INFO - 14:43:14: collected 1279809 word types from a corpus of 5282493 words (unigram + bigrams) and 465505 sentences\n",
      "INFO - 14:43:14: using 1279809 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 14:43:14: source_vocab length 1279809\n",
      "INFO - 14:43:36: Phraser built with 701 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sents_data = [x.split() for x in df_data['text']]\n",
    "phrases_data = Phrases(sents_data, min_count=30, progress_per=10000)\n",
    "\n",
    "bigram_data = Phraser(phrases_data)\n",
    "sentences_data = bigram[sents_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='end' style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#A52A2A;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> Most Frequent Words </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5898"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tesla', 'model', 'elon_musk', 'de', 'sec', 'car', 'tweet', 'la', 'polestar', 'contempt']\n"
     ]
    }
   ],
   "source": [
    "x = sorted(word_freq, key=word_freq.get, reverse=True)[:10]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentences_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sent in sentences_data:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'to', 'the', 'and', 'have', 'not', 'in', 'go', 'get', 'for']\n"
     ]
    }
   ],
   "source": [
    "x = sorted(word_freq, key=word_freq.get, reverse=True)[:10]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='end' style=\"width:100%;height:70px;border: 4px solid #A52A2A;background-color:#A52A2A;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "  <header><h2><b> Training the model </b></h2></header>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #BFE6FF;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    " https://radimrehurek.com/gensim/models/word2vec.html\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 14:44:22: consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=50,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.interfaces.TransformedCorpus object at 0x11f375048>\n"
     ]
    }
   ],
   "source": [
    "print(sentences_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:44:31: collecting all words and their counts\n",
      "INFO - 14:44:31: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 14:44:31: PROGRESS: at sentence #10000, processed 114484 words, keeping 10680 word types\n",
      "INFO - 14:44:32: PROGRESS: at sentence #20000, processed 226968 words, keeping 16113 word types\n",
      "INFO - 14:44:32: PROGRESS: at sentence #30000, processed 340431 words, keeping 20494 word types\n",
      "INFO - 14:44:33: PROGRESS: at sentence #40000, processed 455472 words, keeping 24213 word types\n",
      "INFO - 14:44:33: PROGRESS: at sentence #50000, processed 570772 words, keeping 27934 word types\n",
      "INFO - 14:44:34: PROGRESS: at sentence #60000, processed 684046 words, keeping 31209 word types\n",
      "INFO - 14:44:34: PROGRESS: at sentence #70000, processed 796621 words, keeping 34069 word types\n",
      "INFO - 14:44:35: PROGRESS: at sentence #80000, processed 909398 words, keeping 36857 word types\n",
      "INFO - 14:44:35: PROGRESS: at sentence #90000, processed 1024696 words, keeping 39650 word types\n",
      "INFO - 14:44:36: PROGRESS: at sentence #100000, processed 1139871 words, keeping 42290 word types\n",
      "INFO - 14:44:36: PROGRESS: at sentence #110000, processed 1253366 words, keeping 44884 word types\n",
      "INFO - 14:44:37: PROGRESS: at sentence #120000, processed 1366172 words, keeping 47308 word types\n",
      "INFO - 14:44:38: PROGRESS: at sentence #130000, processed 1480677 words, keeping 49684 word types\n",
      "INFO - 14:44:38: PROGRESS: at sentence #140000, processed 1596778 words, keeping 52065 word types\n",
      "INFO - 14:44:39: PROGRESS: at sentence #150000, processed 1712854 words, keeping 54391 word types\n",
      "INFO - 14:44:40: PROGRESS: at sentence #160000, processed 1826109 words, keeping 56588 word types\n",
      "INFO - 14:44:40: PROGRESS: at sentence #170000, processed 1941306 words, keeping 58778 word types\n",
      "INFO - 14:44:41: PROGRESS: at sentence #180000, processed 2053222 words, keeping 60716 word types\n",
      "INFO - 14:44:41: PROGRESS: at sentence #190000, processed 2165405 words, keeping 62646 word types\n",
      "INFO - 14:44:42: PROGRESS: at sentence #200000, processed 2281010 words, keeping 64825 word types\n",
      "INFO - 14:44:42: PROGRESS: at sentence #210000, processed 2394123 words, keeping 66796 word types\n",
      "INFO - 14:44:43: PROGRESS: at sentence #220000, processed 2504802 words, keeping 68659 word types\n",
      "INFO - 14:44:44: PROGRESS: at sentence #230000, processed 2617357 words, keeping 70542 word types\n",
      "INFO - 14:44:44: PROGRESS: at sentence #240000, processed 2732583 words, keeping 72440 word types\n",
      "INFO - 14:44:45: PROGRESS: at sentence #250000, processed 2844630 words, keeping 74073 word types\n",
      "INFO - 14:44:45: PROGRESS: at sentence #260000, processed 2956830 words, keeping 75623 word types\n",
      "INFO - 14:44:46: PROGRESS: at sentence #270000, processed 3072741 words, keeping 77420 word types\n",
      "INFO - 14:44:46: PROGRESS: at sentence #280000, processed 3187266 words, keeping 79106 word types\n",
      "INFO - 14:44:47: PROGRESS: at sentence #290000, processed 3300235 words, keeping 80726 word types\n",
      "INFO - 14:44:47: PROGRESS: at sentence #300000, processed 3412235 words, keeping 82285 word types\n",
      "INFO - 14:44:48: PROGRESS: at sentence #310000, processed 3527141 words, keeping 83911 word types\n",
      "INFO - 14:44:48: PROGRESS: at sentence #320000, processed 3642055 words, keeping 85602 word types\n",
      "INFO - 14:44:49: PROGRESS: at sentence #330000, processed 3754197 words, keeping 87089 word types\n",
      "INFO - 14:44:50: PROGRESS: at sentence #340000, processed 3870033 words, keeping 88896 word types\n",
      "INFO - 14:44:50: PROGRESS: at sentence #350000, processed 3983825 words, keeping 90418 word types\n",
      "INFO - 14:44:51: PROGRESS: at sentence #360000, processed 4097207 words, keeping 91950 word types\n",
      "INFO - 14:44:51: PROGRESS: at sentence #370000, processed 4207839 words, keeping 93422 word types\n",
      "INFO - 14:44:52: PROGRESS: at sentence #380000, processed 4322343 words, keeping 95150 word types\n",
      "INFO - 14:44:52: PROGRESS: at sentence #390000, processed 4435590 words, keeping 96681 word types\n",
      "INFO - 14:44:53: PROGRESS: at sentence #400000, processed 4548002 words, keeping 98118 word types\n",
      "INFO - 14:44:53: PROGRESS: at sentence #410000, processed 4658361 words, keeping 99585 word types\n",
      "INFO - 14:44:54: PROGRESS: at sentence #420000, processed 4771553 words, keeping 101137 word types\n",
      "INFO - 14:44:54: PROGRESS: at sentence #430000, processed 4883921 words, keeping 102705 word types\n",
      "INFO - 14:44:55: PROGRESS: at sentence #440000, processed 4995450 words, keeping 104146 word types\n",
      "INFO - 14:44:55: PROGRESS: at sentence #450000, processed 5107124 words, keeping 105496 word types\n",
      "INFO - 14:44:55: PROGRESS: at sentence #460000, processed 5220302 words, keeping 107045 word types\n",
      "INFO - 14:44:56: collected 107888 word types from a corpus of 5282487 raw words and 465505 sentences\n",
      "INFO - 14:44:56: Loading a fresh vocabulary\n",
      "INFO - 14:44:56: effective_min_count=20 retains 8634 unique words (8% of original 107888, drops 99254)\n",
      "INFO - 14:44:56: effective_min_count=20 leaves 5045673 word corpus (95% of original 5282487, drops 236814)\n",
      "INFO - 14:44:56: deleting the raw counts dictionary of 107888 items\n",
      "INFO - 14:44:56: sample=6e-05 downsamples 685 most-common words\n",
      "INFO - 14:44:56: downsampling leaves estimated 1817340 word corpus (36.0% of prior 5045673)\n",
      "INFO - 14:44:56: estimated required memory for 8634 words and 50 dimensions: 7770600 bytes\n",
      "INFO - 14:44:56: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "# Building the Vocabulary Table:\n",
    "\"\"\"\n",
    " builds the vocabulary from a sequence of sentences and thus initialized the model. \n",
    "\n",
    "\"\"\"\n",
    "w2v_model.build_vocab(sentences_data, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:45:00: training model with 3 workers on 8634 vocabulary and 50 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:01: EPOCH - 1 : training on 26023 raw words (11164 effective words) took 0.2s, 64663 effective words/s\n",
      "WARNING - 14:45:01: EPOCH - 1 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:01: EPOCH - 2 : training on 26023 raw words (11111 effective words) took 0.1s, 81690 effective words/s\n",
      "WARNING - 14:45:01: EPOCH - 2 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:01: EPOCH - 3 : training on 26023 raw words (11137 effective words) took 0.2s, 69931 effective words/s\n",
      "WARNING - 14:45:01: EPOCH - 3 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:01: EPOCH - 4 : training on 26023 raw words (11118 effective words) took 0.2s, 72755 effective words/s\n",
      "WARNING - 14:45:01: EPOCH - 4 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:01: EPOCH - 5 : training on 26023 raw words (11126 effective words) took 0.2s, 72444 effective words/s\n",
      "WARNING - 14:45:01: EPOCH - 5 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:01: EPOCH - 6 : training on 26023 raw words (11143 effective words) took 0.1s, 79312 effective words/s\n",
      "WARNING - 14:45:01: EPOCH - 6 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:02: EPOCH - 7 : training on 26023 raw words (11117 effective words) took 0.2s, 50028 effective words/s\n",
      "WARNING - 14:45:02: EPOCH - 7 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:02: EPOCH - 8 : training on 26023 raw words (11115 effective words) took 0.3s, 44201 effective words/s\n",
      "WARNING - 14:45:02: EPOCH - 8 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:02: EPOCH - 9 : training on 26023 raw words (11185 effective words) took 0.2s, 46992 effective words/s\n",
      "WARNING - 14:45:02: EPOCH - 9 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:02: EPOCH - 10 : training on 26023 raw words (11098 effective words) took 0.3s, 44018 effective words/s\n",
      "WARNING - 14:45:02: EPOCH - 10 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:03: EPOCH - 11 : training on 26023 raw words (11066 effective words) took 0.1s, 74554 effective words/s\n",
      "WARNING - 14:45:03: EPOCH - 11 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:03: EPOCH - 12 : training on 26023 raw words (11196 effective words) took 0.1s, 77463 effective words/s\n",
      "WARNING - 14:45:03: EPOCH - 12 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:03: EPOCH - 13 : training on 26023 raw words (11186 effective words) took 0.1s, 79534 effective words/s\n",
      "WARNING - 14:45:03: EPOCH - 13 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:03: EPOCH - 14 : training on 26023 raw words (11146 effective words) took 0.2s, 62128 effective words/s\n",
      "WARNING - 14:45:03: EPOCH - 14 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:03: EPOCH - 15 : training on 26023 raw words (11156 effective words) took 0.2s, 45313 effective words/s\n",
      "WARNING - 14:45:03: EPOCH - 15 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:04: EPOCH - 16 : training on 26023 raw words (11171 effective words) took 0.2s, 52033 effective words/s\n",
      "WARNING - 14:45:04: EPOCH - 16 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:04: EPOCH - 17 : training on 26023 raw words (11120 effective words) took 0.2s, 49597 effective words/s\n",
      "WARNING - 14:45:04: EPOCH - 17 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:04: EPOCH - 18 : training on 26023 raw words (11139 effective words) took 0.2s, 46527 effective words/s\n",
      "WARNING - 14:45:04: EPOCH - 18 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:04: EPOCH - 19 : training on 26023 raw words (11081 effective words) took 0.2s, 50805 effective words/s\n",
      "WARNING - 14:45:04: EPOCH - 19 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:05: EPOCH - 20 : training on 26023 raw words (11100 effective words) took 0.2s, 48098 effective words/s\n",
      "WARNING - 14:45:05: EPOCH - 20 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:05: EPOCH - 21 : training on 26023 raw words (11157 effective words) took 0.2s, 51253 effective words/s\n",
      "WARNING - 14:45:05: EPOCH - 21 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:05: EPOCH - 22 : training on 26023 raw words (11158 effective words) took 0.2s, 69999 effective words/s\n",
      "WARNING - 14:45:05: EPOCH - 22 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:05: EPOCH - 23 : training on 26023 raw words (11166 effective words) took 0.1s, 85603 effective words/s\n",
      "WARNING - 14:45:05: EPOCH - 23 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:05: EPOCH - 24 : training on 26023 raw words (11118 effective words) took 0.1s, 76846 effective words/s\n",
      "WARNING - 14:45:05: EPOCH - 24 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:05: EPOCH - 25 : training on 26023 raw words (11134 effective words) took 0.3s, 43259 effective words/s\n",
      "WARNING - 14:45:05: EPOCH - 25 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:06: EPOCH - 26 : training on 26023 raw words (11109 effective words) took 0.2s, 49030 effective words/s\n",
      "WARNING - 14:45:06: EPOCH - 26 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:06: EPOCH - 27 : training on 26023 raw words (11130 effective words) took 0.2s, 49340 effective words/s\n",
      "WARNING - 14:45:06: EPOCH - 27 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:06: EPOCH - 28 : training on 26023 raw words (11185 effective words) took 0.2s, 62775 effective words/s\n",
      "WARNING - 14:45:06: EPOCH - 28 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:06: EPOCH - 29 : training on 26023 raw words (11186 effective words) took 0.2s, 46389 effective words/s\n",
      "WARNING - 14:45:06: EPOCH - 29 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 14:45:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 14:45:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 14:45:07: EPOCH - 30 : training on 26023 raw words (11185 effective words) took 0.2s, 49775 effective words/s\n",
      "WARNING - 14:45:07: EPOCH - 30 : supplied example count (2816) did not equal expected count (465505)\n",
      "INFO - 14:45:07: training on a 780690 raw words (334203 effective words) took 6.3s, 53104 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(334203, 780690)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings('error')\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_tmpfile(\"wordvectors.kv\")\n",
    "model.wv.save(path)\n",
    "# save_word2vec_format(fname, fvocab=None, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we do not plan to train the model any further, we are calling init_sims(), which will make the model much more memory-efficient:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 14:46:37: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FutureWarning",
     "evalue": "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFutureWarning\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-87d3ab31cabc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# see what we get for the show's main character:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hey\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36munitvec\u001b[0;34m(vec, norm, return_norm)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mveclen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblas_nrm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mveclen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mconcrete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 ),\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             )\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFutureWarning\u001b[0m: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`."
     ]
    }
   ],
   "source": [
    "# see what we get for the show's main character:\n",
    "w2v_model.wv.most_similar(positive=[\"hey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'homer_simpson' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-70182afc9d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"homer_simpson\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'homer_simpson' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"marge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"bart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how similar are two words to each other\n",
    "w2v_model.wv.similarity(\"moe_'s\", 'tavern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "FutureWarning",
     "evalue": "Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFutureWarning\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-94acca17a779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tesla'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/matutils.py\u001b[0m in \u001b[0;36munitvec\u001b[0;34m(vec, norm, return_norm)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0mveclen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblas_nrm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mveclen\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mconcrete\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2_orig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 ),\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m             )\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFutureWarning\u001b[0m: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`."
     ]
    }
   ],
   "source": [
    "w2v_model.wv.similarity('tesla', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.similarity('bart', 'nelson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask our model to give us the word that does not belong to the list\n",
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"layers\" style=\"width:100%;height:70px;border: 4px solid #179871;background-color:#179871;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1>+PLus Theory<h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **min_count =** int - Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "- **window =** int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)\n",
    "- **size =** int - Dimensionality of the feature vectors. - (50, 300)\n",
    "- **size =** int - Dimensionality of the feature vectors. - (50, 300)\n",
    "- **alpha =** float - The initial learning rate - (0.01, 0.05)\n",
    "- **min_alpha =** float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
    "- **negative =** int - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
    "- **workers =** int - Use these many worker threads to train the model (=faster training with multicore machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
