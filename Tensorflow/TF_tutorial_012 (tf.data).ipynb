{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:atuo;text-align:center;border: 4px solid black;background-color:#FF8000;color:white;border-radius: 25px\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:4px 4px 4px 4px;padding:0.3%;margin:19px;background-image: url(https://www.tensorflow.org/images/tf_logo_social.png);background-repeat: no-repeat;background-size: 320px\"> \n",
    "<header style=\"width:100%;height:auto;\">\n",
    "  <font size=\"23px\"><b> Chapter 00</b></font>\n",
    "    <h2> Tensorflow_tutorial </h2>\n",
    "    <h4> </h4>\n",
    "</header>\n",
    "\n",
    "<div><div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #FF8000;padding:9px;'>\n",
    "<div style=\"box-shadow: 0 8px 12px 0 white, 0 6px 20px 0 rgba(1, 1, 1, 1);padding:1%;margin:6px;border-radius: 25px\"> \n",
    "    \n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px;opacity: 0.9;\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px\">    \n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "+\n",
    "\n",
    "    \n",
    "\n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px;box-shadow: 0 1px 1px 0 #00264D, 0 6px 20px 0 rgba(1, 1, 1, 1)\">\n",
    "<div style=\"box-shadow: 0 1px 8px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px;width:10%;text-align:center\">    \n",
    "  <strong> Refrence: </strong><br></div>  \n",
    "<div style=\"box-shadow: 0 1px 12px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px;margin-top:8px\">      \n",
    "\n",
    "+ https://cs230-stanford.github.io/tensorflow-input-data.html \n",
    "    \n",
    "+ https://www.kaggle.com/kmader/tf-data-tutorial-with-retina-and-keras\n",
    "    \n",
    "+ https://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428\n",
    "    \n",
    "+ https://www.youtube.com/watch?v=kVEOCfBy9uY    \n",
    "    \n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#CC8800;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px\">       \n",
    "  <strong> Summary: </strong><br>\n",
    "    \n",
    "        \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:25%;height:30px;border: 4px solid black;background-color:#990000;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h5> contents-Paper:  </h5>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#FF8000;color:black;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#FF8000;color:black;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#\" style=\"position: relative;padding:5px;color:white;text-align: center;\">   </a></h6>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#990000;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> :  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"\" style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:5%;height:28px;border: 4px solid black;background-color:#FF8000;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 #FF8000, 0 6px 20px 0 rgba(0, 0, 0, 0.19)\">\n",
    "    <h5>   </h5>\n",
    "</div>\n",
    "<div style=\"position:absolute;width:40%;height:28px;border: 4px solid black;background-color:#990000;color:white;text-align:center;border-radius:0px 45px 45px 0px;padding:3px;left:6.5%;box-shadow: 0 4px 8px 0 #990000, 0 6px 20px 0 rgba(0, 0, 0, 0.19)\">\n",
    "    <h5> Abstract: </h5>\n",
    "</div>    \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#990000;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>   </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid #00264D;box-shadow: 0 4px 8px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:0.6%\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;border-radius: 15px\">\n",
    "     \n",
    "    \n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"\"  style=\"height:55px\">\n",
    "<div style=\"position:absolute;width:40%;height:40px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:0 25px 25px 0;\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 white, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:0.1%;margin:1px;border-radius: 25px;height:5px \">     \n",
    "    <h5> Abstract  </h5>\n",
    "</div>\n",
    "</div>   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:98%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>   </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:5%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;bbox-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);background-image: url(https://res.cloudinary.com/teepublic/image/private/s--gXhIdxfR--/t_Preview/b_rgb:191919,c_limit,f_jpg,h_630,q_90,w_630/v1548944515/production/designs/4119630_0.jpg);background-repeat: repeat;background-size: 40%\">\n",
    "    <h5>   </h5>\n",
    "</div>\n",
    "<div id=\"\"  style=\"position:absolute;width:40%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 1px 0px 0px;padding:3px;left:11.5%;bbox-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);\">\n",
    "    <h5> : </h5>\n",
    "</div>  \n",
    "<div id=\"\"  style=\"position:absolute;width:1%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 95px 95px 0px;padding:3px;left:52.7%;bbox-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);\">\n",
    "    <h5> </h5>\n",
    "</div>     \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:70%;border: 5px solid #00264D;box-shadow: 0 4px 8px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:0.6%\">\n",
    "<div style=\"height:154px\">\n",
    "<img src=\"http://juditacs.github.io/assets/padded_sequence.png\" style=\"position:absoluate;height:150px;border:3px solid #1E00B3\">\n",
    "<img src=\"http://juditacs.github.io/assets/softmax_before_after.png\" style=\"position:absoluate;height:150px;border:3px solid #1E00B3\">\n",
    "   \n",
    "</div>\n",
    "\n",
    "<div style=\"height:30px\">\n",
    "<div style=\"width:22%;text-align:center;position:absolute;left:1.3%;border:3px solid #1E00B3\"><b>Mask(or Padding)</b></div> \n",
    "<div style=\"width:22.2%;text-align:center;position:absolute;left:24.1%;border:3px solid #1E00B3\"><b>Whithout mask</b></div>\n",
    "<div style=\"width:21.2%;text-align:center;position:absolute;left:47.1%;border:3px solid #1E00B3\"><b>with mask</b></div>     \n",
    "   \n",
    "</div>\n",
    "<div style=\"height:30px\">\n",
    "<div style=\"width:67%;text-align:center;position:absolute;left:1.3%;border:3px solid #00264D\"><b>fig24</b></div>     \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"1\" style=\"width:100%;height:atuo;border: 4px solid black;background-color:#FF8000;color:black;text-align:center;border-radius: 25px;padding:3px\">\n",
    "<div style=\"box-shadow: 0 1px 4px 0 #00264D, 0 60px 20px 0 rgba(1, 1, 1, 1);padding:0.5%;margin:6px;border-radius: 25px\"> \n",
    "           \n",
    "<h4><b>  </b></h4>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px\">    \n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "- TensorFlow Dev Summit 2018: https://www.youtube.com/watch?v=uIcqeP7MFH0\n",
    "\n",
    "    \n",
    "\n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#CC8800;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px\">       \n",
    "  <strong> Summary: </strong><br>\n",
    "    \n",
    "        \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile TF_tutrial_CNN_B.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from farhad.utility import encode_text_dummy_array\n",
    "from farhad.time_estimate import EstimateFaster\n",
    "\n",
    "import numpy as np \n",
    "path_tb = 'log/6/'\n",
    "def conv2d(inputs, channel_in, channel_out,name):\n",
    "    #\n",
    "    with tf.name_scope('conv2D_{}'.format(name)):\n",
    "        w = tf.Variable(tf.zeros(shape=[3,3,channel_in,channel_out]),name='w_conv')\n",
    "        b = tf.Variable(tf.zeros(shape=[channel_out]), name='b_conv')\n",
    "        conv2 = tf.nn.conv2d(inputs, w, strides=[1,1,1,1], padding=\"SAME\", name='conv2d_conv')\n",
    "        act = tf.nn.relu(conv2+b)\n",
    "        \n",
    "        tf.summary.histogram(path_tb+\"w_conv\"+name, w)\n",
    "        tf.summary.histogram(path_tb+\"b_conv\"+name,b)\n",
    "        tf.summary.histogram(path_tb+\"act_conv\"+name,act)\n",
    "        \n",
    "        return act\n",
    "    \n",
    "def feedforward(inputs, units , name):\n",
    "    with tf.name_scope('feedforeard{}'.format(name)):\n",
    "        w = tf.Variable(tf.zeros(shape=[inputs.shape[1], units]),name='w_ff')\n",
    "        b = tf.Variable(tf.zeros(shape=[units]),name='b_ff')\n",
    "        ma = tf.matmul(inputs,w)\n",
    "        act = tf.nn.relu(ma+b, name=\"act_ff\")\n",
    "        \n",
    "        tf.summary.histogram(path_tb+\"w_ff\"+name, w)\n",
    "        tf.summary.histogram(path_tb+\"b_ff\"+name,b)\n",
    "        tf.summary.histogram(path_tb+\"act_ff\"+name,act)\n",
    "        \n",
    "        return act\n",
    "            \n",
    "def write_graph(sess, name):\n",
    "    join = os.path.join(path_tb, name)\n",
    "    file_writer = tf.summary.FileWriter(join)\n",
    "    file_writer.add_graph(sess.graph)\n",
    "    \n",
    "class Dataset:\n",
    "    def __init__(self,data):\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_completed = 0\n",
    "        self._data = data\n",
    "        self._num_examples = data.shape[0]\n",
    "        pass\n",
    "\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "\n",
    "    def next_batch(self,batch_size,shuffle = True):\n",
    "        start = self._index_in_epoch\n",
    "        if start == 0 and self._epochs_completed == 0:\n",
    "            idx = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx)  # shuffle indexe\n",
    "            self._data = self.data[idx]  # get list of `num` random samples\n",
    "\n",
    "        # go to the next batch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            data_rest_part = self.data[start:self._num_examples]\n",
    "            idx0 = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx0)  # shuffle indexes\n",
    "            self._data = self.data[idx0]  # get list of `num` random samples\n",
    "\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples #avoid the case where the #sample != integar times of batch_size\n",
    "            end =  self._index_in_epoch  \n",
    "            data_new_part =  self._data[start:end]  \n",
    "            return np.concatenate((data_rest_part, data_new_part), axis=0)\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            return self._data[start:end]\n",
    "\n",
    "\n",
    "class mnist_model():\n",
    "    def __init__(self,intputs):\n",
    "        self.sess =  tf.Session()\n",
    "        \n",
    "       \n",
    "        self.pred = ''\n",
    "        \n",
    "        self.cross_entropy= ''\n",
    "        self.train_step =''\n",
    "        self.accuracy = ''\n",
    "        self.summ =\"\"\n",
    "        self.writer = \"\"\n",
    "        self.intputs = intputs\n",
    "    \n",
    "        self.x = tf.placeholder(shape=[None,28,28],dtype=tf.float32, name='as_inputs')\n",
    "        self.x_image = tf.reshape(self.x, [-1,28,28,1])\n",
    "        tf.summary.image(path_tb+'as_inputs',self.x, 3)\n",
    "    \n",
    "        self.y = tf.placeholder(shape=[None,10],dtype=tf.float32, name=\"as_outputs\")\n",
    "    \n",
    "        conv_1 = conv2d(inputs=self.x_image, channel_in=1, channel_out=32,name=\"conv1\")\n",
    "        pool_1 = tf.nn.max_pool(conv_1, ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    \n",
    "        Flatten_shape = [-1, (14)*(14)*32] #14/2\n",
    "        Flatten_1 = tf.reshape(pool_1, shape=Flatten_shape , name=\"Flatten\")\n",
    "    \n",
    "        ff_1 = feedforward(Flatten_1, units=128, name=\"ff_1\")\n",
    "        ff_2 = feedforward(ff_1, units=10, name=\"ff_2\")\n",
    "        ff_3 = tf.nn.softmax(ff_2, name=\"softmax_layer\")\n",
    "    \n",
    "        tf.summary.histogram(path_tb+'softmax',ff_3)\n",
    "        self.pred = ff_3\n",
    "        \n",
    "    \n",
    "    def compiles(self,learning_rate=1e-4):\n",
    "        \n",
    "        with tf.name_scope('Losses_funcation'):\n",
    "            self.cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.pred, labels=self.y), name=\"cross_entropy\")\n",
    "            tf.summary.scalar(path_tb+'cross_entropy', self.cross_entropy)\n",
    "            \n",
    "        with tf.name_scope('optimizer'):\n",
    "            self.train_step = tf.train.AdamOptimizer(learning_rate).minimize(self.cross_entropy)\n",
    "            \n",
    "        \n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_prediction = tf.equal(tf.argmax(self.pred, 1), tf.argmax(self.y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))   \n",
    "            tf.summary.scalar(path_tb+\"accuracy\", self.accuracy)\n",
    "        \n",
    "        self.summ = tf.summary.merge_all() \n",
    "        self.saver = tf.train.Saver()        \n",
    "        \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        write_graph(self.sess, 'model')\n",
    "        \n",
    "    def make_hparam_string(learning_rate, use_two_fc=False, use_two_conv=False):\n",
    "        conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "        fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "        return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "    \n",
    "    def next_batch(self,num, data, labels):\n",
    "        '''\n",
    "        Return a total of `num` random samples and labels. \n",
    "        '''\n",
    "        idx = np.arange(0 , len(data))\n",
    "        np.random.shuffle(idx)\n",
    "        idx = idx[:num]\n",
    "        data_shuffle = [data[ i] for i in idx]\n",
    "        labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "        return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "    \n",
    "    def fit(self, dataset , validation_size=0.20 , epoch=1000 ,verbose=0 , batch=90):\n",
    "\n",
    "        \n",
    "        #inputs = inputs.suffle(32) \n",
    "        \n",
    "        for i  in epoch:\n",
    "            \n",
    "            \n",
    "            if i % 5 == 0:\n",
    "                [train_accuracy, s] = self.sess.run([self.accuracy, self.summ], feed_dict={self.x: dataset[\"features\"][0], self.y: y_train[\"label\"][0]})\n",
    "                \n",
    "            if  verbose==1 and i % 5 == 0:\n",
    "                con = int((i+1)*50/epoch)\n",
    "                con_ant = 50-con\n",
    "                #run = \"[step:\"+str(i)+\"/\"+str(epoch)+\"|\"+\"|\"+\"[training accuracy:\"+str(train_accuracy)+\"] \\n\"\n",
    "                sys.stdout.write(\"[step: {}/{}]|{}{}|[training accuracy: {}] \\n\".format(i,epoch,con*'#',con_ant*' ',train_accuracy))\n",
    "                #sys.stdout.write(run)\n",
    "            if i % 10 == 0:\n",
    "                #self.sess.run(feed_dict={self.x: X_test, self.y: y_test}) #assignment, \n",
    "                self.saver.save(self.sess, os.path.join(path_tb, \"model.ckpt\"), i)\n",
    "                #write_graph(self.sess, str(i))\n",
    "                \n",
    "            self.sess.run(self.train_step, feed_dict={self.x: dataset[\"features\"][0], self.y: dataset[\"label\"][0]})\n",
    "            try:\n",
    "                self.writer = tf.summary.FileWriter(path_tb + hparam)\n",
    "            except:\n",
    "                self.writer = tf.summary.FileWriter(path_tb + 'model')\n",
    "            EstimateFaster(i,epoch,\"process is runing,training_accuracy:{}\".format(train_accuracy))\n",
    "            print('last accuracy:', train_accuracy)\n",
    "    def MAIN(self,x_train, y_train):\n",
    "        dataset = {\"features\":x_train, \"label\":y_train}\n",
    "        dataset = tf.data.Dataset.from_tensors(dataset)\n",
    "        dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.batch(100)\n",
    "        dataset.map(self.fit)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TF_tutrial_CNN_B as TF_B\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from farhad.utility import encode_text_dummy_array\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.enable_eager_execution()\n",
    "path_tb = 'log/5/'\n",
    "train, test = mnist.load_data()\n",
    "x_train, y_train= train \n",
    "x_test, y_test = test\n",
    "\n",
    "x_train, x_test= x_train/255.0, x_test/255.0 \n",
    "y_train, y_test =  encode_text_dummy_array(y_train).values, encode_text_dummy_array(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d6fd0232b7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#model.fit(dataset, epoch=epoch, verbose=0, batch=batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAIN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e9055ba2ade6>\u001b[0m in \u001b[0;36mMAIN\u001b[0;34m(self, x_train, y_train)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \"\"\"\n\u001b[1;32m    985\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m     wrapped_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 2198\u001b[0;31m         map_func, \"Dataset.map()\", input_dataset)\n\u001b[0m\u001b[1;32m   2199\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, add_to_graph, experimental_nested_dataset_support)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1455\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m       \u001b[0;31m# Use the private method that will execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# Adds this function into 'g'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     temp_graph = func_graph_from_py_func(\n\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;31m# Call func and gather the output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     \u001b[0;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e9055ba2ade6>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, validation_size, epoch, verbose, batch)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;31m#inputs = inputs.suffle(32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "epoch = 2000\n",
    "batch = 1000\n",
    "\n",
    "model = mnist_model(x_train)\n",
    "model.compiles(learning_rate=learning_rate)\n",
    "#model.fit(dataset, epoch=epoch, verbose=0, batch=batch)\n",
    "model.MAIN(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test = tf.data.Dataset.from_tensors(x_train), tf.data.Dataset.from_tensors(x_test)\n",
    "#y_train, y_test  = tf.data.Dataset.from_tensors(y_train), tf.data.Dataset.from_tensors(y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"features\":x_train, \"label\":y_train}\n",
    "dataset = tf.data.Dataset.from_tensors(dataset)\n",
    "dataset = dataset.shuffle(1000)\n",
    "dataset = dataset.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epoch = 2000\n",
    "batch = 1000\n",
    "\n",
    "model = TF_B.mnist_model(x_train)\n",
    "model.compiles(learning_rate=learning_rate)\n",
    "#model.fit(dataset, epoch=epoch, verbose=0, batch=batch)\n",
    "model.MAIN(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.estimator.Estimator(model_fn= model.fit).train(input_fn=x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\"x\": [[1,2,3],[4,5,6],[7,8,9],[10,11,12]], \"y\":[['A'],['B'],['C'],['D']]}\n",
    "data = tf.data.Dataset.from_tensors(data)\n",
    "data = data.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[b'A']\n",
      " [b'B']\n",
      " [b'C']\n",
      " [b'D']], shape=(4, 1), dtype=string)\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    print(i['y'][0])\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6a2a50a8d325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:98%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>   </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(file)\n",
    "dataset = dataset.shuffle(32)\n",
    "dataset = dataset.map(lambda recotd: parse(record))\n",
    "dataset = dataset.batch(BATACH_SIZE)\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "get_next = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    try:\n",
    "        images, label = sess.run(get_next)\n",
    "        \n",
    "        \"\"\"  ... \"\"\"\n",
    "        \n",
    "    except error.OutOfRangeError:\n",
    "        pass\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
