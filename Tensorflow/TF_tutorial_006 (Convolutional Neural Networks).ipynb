{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:atuo;text-align:center;border: 4px solid black;background-color:#FF8000;color:white;border-radius: 25px\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:4px 4px 4px 4px;padding:0.3%;margin:19px;background-image: url(https://www.tensorflow.org/images/tf_logo_social.png);background-repeat: no-repeat;background-size: 324px\"> \n",
    "<header style=\"width:100%;height:auto;\">\n",
    "  <font size=\"23px\"><b> Chapter 005</b></font>\n",
    "    <h2> Tensorflow_tutorial </h2>\n",
    "    <h4> Mnist,Convolutional Neural Networks </h4>\n",
    "</header>\n",
    "\n",
    "<div><div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #FF8000;padding:9px;'>\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px\"> \n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid black;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px;opacity: 0.9;\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px\">    \n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "+ https://www.quora.com/What-are-some-good-books-on-TensorFlow\n",
    "    \n",
    "+ http://library1.org/_ads/CC9F36A65079BF244E0CE0649D274CD9    \n",
    "\n",
    "+ https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b    \n",
    "    \n",
    "\n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:25%;height:30px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h5> contents:  </h5>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#FF8000;color:black;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#1\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Summaries and TensorBoard  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:5px 5px 5px 5px;padding:3px\">\n",
    "    <h6><a href=\"#2\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Abstract:  </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:white;color:white;text-align:center;border-radius:8px 8px 8px 8px;padding:3px\">\n",
    "    <h6><a href=\"#3\" style=\"position: relative;padding:5px;color:white;text-align: center;\">   </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:8px 8px 8px 8px;padding:3px\">\n",
    "    <h6><a href=\"#4\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Hands-on TensorBoard (TensorFlow Dev Summit 2017): </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#5\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Load data:: </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#6\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Layer difinition::  </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#7\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  loss and training::  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#8\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> loss and training:  </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:white;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#8\" style=\"position: relative;padding:5px;color:white;text-align: center;\">   </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#9\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Modified fro better visulation::  </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#10\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Hyperparameter Search::  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:white;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#\" style=\"position: relative;padding:5px;color:white;text-align: center;\">   </a></h6>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"1\" style=\"width:100%;height:atuo;border: 4px solid black;background-color:#FF8000;color:black;text-align:center;border-radius: 25px;padding:3px\">\n",
    "<div style=\"box-shadow: 0 1px 4px 0 #00264D, 0 60px 20px 0 rgba(1, 1, 1, 1);padding:0.5%;margin:6px;border-radius: 25px\"> \n",
    "           \n",
    "<h4><b>  Summaries and TensorBoard </b></h4>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px;box-shadow: 0 1px 1px 0 #00264D, 0 6px 20px 0 rgba(1, 1, 1, 1)\">\n",
    "<div style=\"box-shadow: 0 1px 4px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px;width:10%;text-align:center\">    \n",
    "  <strong> Refrence: </strong><br></div>  \n",
    "<div style=\"box-shadow: 0 1px 12px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px;margin-top:8px\">      \n",
    "\n",
    "1. code: https://www.youtube.com/watch?v=eBbEDRsCmv4    \n",
    "    \n",
    "+ code: https://github.com/martinwicke/tf-dev-summit-tensorboard-tutorial    \n",
    "\n",
    "+ Theory: https://www.jessicayung.com/explaining-tensorflow-code-for-a-convolutional-neural-network/    \n",
    "</div>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#CC8800;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "<div style=\"box-shadow: 0 14px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;margin:6px;border-radius: 25px\">       \n",
    "  <strong> Summary: </strong><br>\n",
    "    \n",
    "        \n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"\"  style=\"height:56px\">\n",
    "<div style=\"position:absolute;width:98%;height:48px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h3><b>  Abstract: </b></h3>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sess = tf.InteractiveSession()\n",
    "t = tf.Variable(np.array([1, 2, 3, 4]), name=\"1\")\n",
    "t_re = tf.reshape(t, shape = [-1,2,2,1])    \n",
    "print(t_re.shape)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "t = tf.Variable(np.array([1, 2, 3, 4]), name=\"1\")\n",
    "t_re = tf.reshape(t, shape = [-1,2,2,1])    \n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(t_re.shape)\n",
    "b = t_re.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"4\"  style=\"height:56px\">\n",
    "<div style=\"position:absolute;width:98%;height:48px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h3><b>  Hands-on TensorBoard (TensorFlow Dev Summit 2017) </b></h3>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid #00264D;box-shadow: 0 4px 8px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:0.6%\">\n",
    "<div style=\"box-shadow: 0 4px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:1%;border-radius:35px\">\n",
    "\n",
    "<div style=\"width:70%;border: 5px solid #00264D;box-shadow: 0 4px 8px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:0.6%;border-radius:35px\">\n",
    "<div style=\"height:atuo\">\n",
    "<img src=\"https://i0.wp.com/www.jessicayung.com/wp-content/uploads/2017/05/cnn-1.png?w=1692\" style=\"position:absoluate;height:350px;border:3px solid #1E00B3\">\n",
    "<img src=\"https://i0.wp.com/www.jessicayung.com/wp-content/uploads/2017/05/cnn-2.png?w=1692\" style=\"position:absoluate;height:350px;border:3px solid #1E00B3\">\n",
    "   \n",
    "</div>\n",
    "\n",
    "<div style=\"height:30px\">\n",
    "<div style=\"width:50%;text-align:center;position:absolute;left:6.3%;border:3px solid #1E00B3\"><b>Convluation [REF3]</b></div> \n",
    "    \n",
    "   \n",
    "</div>\n",
    "<div style=\"height:30px\">\n",
    "<div style=\"width:50%;text-align:center;position:absolute;left:6.3%;border:3px solid #00264D\"><b>fig1</b></div>     \n",
    "</div>\n",
    "</div>\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid #00264D;box-shadow: 0 4px 8px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:0.9%\">\n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px\">`\n",
    "\n",
    "```python\n",
    "    \n",
    "w = tf.Variable(tf.zeros(shape=[5,5, channels_in,channels_out]), name=\"W\") # it is used as kernel\n",
    "    \n",
    "kernel_shape = [filter_height, filter_width, in_channels, out_channels]\n",
    "```    \n",
    "- filter: A Tensor. Must have the same type as input. A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    \n",
    "    \n",
    "</div>\n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "inputs  = tf.placeholder(dtype=tf.float32, shape=[None,784], name='inputs')\n",
    "inputs = tf.reshape(inputs, shape = [-1,28,28,1])    \n",
    "    \n",
    "```       \n",
    "shape = [batch, in_height, in_width, in_channels] <br>\n",
    "<font color=\"red\">why 784</font>  <br>\n",
    "<font color=\"red\">why batch=-1</font>        \n",
    "</div>       \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "    \n",
    "conv2 = tf.nn.conv2d(inputs, w, strides=[1,1,1,1], padding='SAME')     \n",
    "```       \n",
    "- input_shape = [batch, in_height, in_width, in_channels]   (shape = [-1,28,28,1]) \n",
    "- kernel_shape = [filter_height, filter_width, in_channels, out_channels]  , <br>\n",
    "   <b>(w_shape=[5,5,1,32]for first Conv2d, w_shape=[5,5,32,64]for second Conv2d)</b>   \n",
    "- Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].    \n",
    "- input: A Tensor. Must be one of the following types: half, bfloat16, float32, float64. A 4-D tensor.    \n",
    "- filter: A Tensor. Must have the same type as input. A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]   \n",
    "- strides: A list of ints. 1-D tensor of length 4. The stride of the sliding window for each dimension of input, s=[batch,x,y, channels]<br>\n",
    "    https://stackoverflow.com/questions/34642595/tensorflow-strides-argument\n",
    "    \n",
    "</div>\n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "pool_2 = tf.nn.max_pool(conv2_1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")    \n",
    "tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC',name=None)    \n",
    "```       \n",
    "- value: A 4-D Tensor of the format specified by data_format. [batch, in_height, in_width, in_chanels],\n",
    "- ksize: A list or tuple of 4 ints. The size of the window for each dimension of the input tensor. [filter_height, filter_width, in_channels, out_channels]\n",
    "- strides: A list or tuple of 4 ints. The stride of the sliding window for each dimension of the input tensor.    \n",
    "- <font color=\"red\">data_format: A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.</font>    \n",
    "</div>    \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "flattened = tf.reshape(pool_2, [-1, 7*7*64])    \n",
    "    \n",
    "```  \n",
    "</div> \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "# compute loss    \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"cross_entropy\")    \n",
    "```       \n",
    "    \n",
    "</div> \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "# use Adam optimizer:    \n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)    \n",
    "```       \n",
    "    \n",
    "</div> \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "    \n",
    "# compute accuracy     \n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))       \n",
    "```       \n",
    "    \n",
    "</div>    \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "    \n",
    "## <font color='red'>problem?</font>\n",
    "    \n",
    "```python\n",
    "def make_hparam_string(learning_rate, use_two_fc=True, use_two_conv=True):\n",
    "    conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "    fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "    return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)    \n",
    "hparam = make_hparam_string(learning_rate, use_two_fc=True, use_two_conv=True)      \n",
    "```       \n",
    "    \n",
    "</div> \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "## <font color='red'>problem?</font>\n",
    "    \n",
    "```python\n",
    "embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "assignment = embedding.assign(embedding_input)    \n",
    "    \n",
    "```       \n",
    "    \n",
    "</div> \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "## <font color='red'>problem?</font>    \n",
    "```python\n",
    "  \n",
    "config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "embedding_config = config.embeddings.add()\n",
    "embedding_config.tensor_name = embedding.name\n",
    "embedding_config.sprite.image_path = SPRITES\n",
    "embedding_config.metadata_path = LABELS\n",
    "# Specify the width and height of a single thumbnail.\n",
    "embedding_config.sprite.single_image_dim.extend([28, 28])    \n",
    "```       \n",
    "- It is for embedding visualization in tensorboard    \n",
    "</div> \n",
    "<div style=\"box-shadow: 0 3px 18px 0 #00264D, 0 6px 20px 0 rgba(0, 0, 0, 0.19);padding:2%;border-radius:35px;padding-right:30px;margin-top:12px\">\n",
    "\n",
    "```python\n",
    "    \n",
    "saver = tf.train.Saver()    \n",
    "```       \n",
    "- The Saver class adds ops to save and restore variables to and from checkpoints. It also provides convenience methods to run these ops.    \n",
    "</div>    \n",
    "  \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"5\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:30%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>  Load data: </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c104e94c88ac>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/mnist_tutorial/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/mnist_tutorial/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Necessary data files were not found. Run this command from inside the repo provided at https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial.\n"
     ]
    }
   ],
   "source": [
    "LOGDIR = \"/tmp/mnist_tutorial/\"\n",
    "LABELS = os.path.join(os.getcwd(), \"labels_1024.tsv\")\n",
    "SPRITES = os.path.join(os.getcwd(), \"sprite_1024.png\")\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + \"data\", one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "\n",
    "if not (os.path.isfile(LABELS) and os.path.isfile(SPRITES)):\n",
    "    print(\"Necessary data files were not found. Run this command from inside the \"\n",
    "    \"repo provided at \"\n",
    "    \"https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial.\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"6\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:30%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>  Layer difinition: </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple convoluational layers:\n",
    "def conv2_layer(inputs, channels_in,channels_out,name=\"conv2d\")\n",
    "    w = tf.Variable(tf.zeros(shape=[5,5, channels_in,channels_out]), name=\"W\") #tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1)\n",
    "    b = tf.Variable(tf.zeros(shape=[channels_out]), name=\"b\")\n",
    "    conv2 = tf.nn.conv2d(inputs, w, strides=[1,1,1,1], padding='SAME') \n",
    "    act = tf.nn.relu(conv2+b)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deine a fully connected layer:\n",
    "def fc_layer(inputs, channels_in, channels_out,name=\"fc\"):\n",
    "    w = tf.Variable(tf.zeros(shape=[channels_in, channels_out]),name='W') #tf.truncated_normal([size_in, size_out], stddev=0.1)\n",
    "    b = tf.Variable(tf.zeros(shape=[channels_out]), name='b')\n",
    "    \n",
    "    act = tf.nn.relu(tf.matmul(inputs,w)+b)\n",
    "       \n",
    "    return act\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"7\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:30%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>  loss and training: </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_model(learning_rate, use_two_fc=True, use_two_conv=True):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # feed foeward nerual netwrok:\n",
    "    x  = tf.placeholder(dtype=tf.float32, shape=[None,784], name='inputs')\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    \n",
    "    \n",
    "    y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='labels')\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    if use_two_conv:\n",
    "        # Load first Conveloutional network :\n",
    "        conv2_1 = conv2_layer(x_image, 1,32)\n",
    "        pool_1 = tf.nn.max_pool(conv2_1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    \n",
    "        # Load second Conveloutional network :\n",
    "        conv2_2 = conv2_layer(pool_1, 32, 64)\n",
    "        pool_2 = tf.nn.max_pool(conv2_2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "        flattened = tf.reshape(pool_2, [-1, 7*7*64])\n",
    "    else:\n",
    "        # Load first Conveloutional network :\n",
    "        conv2_1 = conv2_layer(x_image, 1,32)\n",
    "        pool_2 = tf.nn.max_pool(conv2_1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "    if use_two_fc:\n",
    "        # feed-forward nerual network:\n",
    "        fc_1 = fc_layer(flattened, 7*7*64, 1024)\n",
    "        relu = tf.nn.relu(fc_1)\n",
    "        embedding_input = relu\n",
    "        embedding_size = 1024\n",
    "        logits = fc_layer(relu, 1024, 10, \"fc2\")\n",
    "\n",
    "        \n",
    "    else:\n",
    "        embedding_input = flattened\n",
    "        embedding_size = 7*7*64\n",
    "        logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "    return logits,x, y, embedding_size ,embedding_input,sess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute loss funcation as loss funcation\n",
    "def compiles(learning_rate,logits, y):\n",
    " \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"cross_entropy\")\n",
    "        \n",
    "    \n",
    "    # use Adam optimizer:\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    \n",
    "    # compute accuracy     \n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))   \n",
    "        \n",
    "    return cross_entropy,train_step,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hparam_string(learning_rate, use_two_fc=True, use_two_conv=True):\n",
    "    conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "    fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "    return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "logits,x, y, embedding_size, embedding_input,sess = mnist_model(learning_rate)\n",
    "cross_entropy,train_step,accuracy = compiles(learning_rate,logits=logits, y=y)\n",
    "embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "assignment = embedding.assign(embedding_input)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intitialize all the variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "hparam = make_hparam_string(learning_rate, use_two_fc=True, use_two_conv=True)\n",
    "\n",
    "\n",
    "\n",
    "config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "embedding_config = config.embeddings.add()\n",
    "embedding_config.tensor_name = embedding.name\n",
    "embedding_config.sprite.image_path = SPRITES\n",
    "embedding_config.metadata_path = LABELS\n",
    "# Specify the width and height of a single thumbnail.\n",
    "embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.14\n",
      "step 30, training accuracy 0.07\n",
      "step 60, training accuracy 0.1\n",
      "step 90, training accuracy 0.07\n",
      "step 120, training accuracy 0.05\n",
      "step 150, training accuracy 0.15\n",
      "step 180, training accuracy 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train for 2000 steps\n",
    "for i in range(201):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    \n",
    "    if i % 30 == 0:\n",
    "        [train_accuracy] = sess.run([accuracy], feed_dict={x: batch[0], y: batch[1]})\n",
    "        \n",
    "        sys.stdout.write(\"step %d, training accuracy %g\"%(i,train_accuracy))\n",
    "        \n",
    "    if i % 500 == 0:\n",
    "        sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "        saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "        \n",
    "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"7\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:30%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>  Hyperparameter Search: </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # You can try adding some more learning rates\n",
    "    for learning_rate in [1E-3, 1E-4]:\n",
    "        # Include \"False\" as a value to try different model architectures\n",
    "        for use_two_fc in [True]:\n",
    "            for use_two_conv in [False, True]:\n",
    "                # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2\")\n",
    "                hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "                print('Starting run for %s' % hparam)\n",
    "\n",
    "                # Actually run with the new settings\n",
    "                mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done training!')\n",
    "print('Run `tensorboard --logdir=%s` to see the results.' % LOGDIR)\n",
    "print('Running on mac? If you want to get rid of the dialogue asking to give '\n",
    "        'network permissions to TensorBoard, you can provide this flag: '\n",
    "        '--host=localhost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"9\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:99%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>  Modified fro better visulation: </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist_tutorial/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist_tutorial/data/t10k-labels-idx1-ubyte.gz\n",
      "Necessary data files were not found. Run this command from inside the repo provided at https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial.\n",
      "Starting run for lr_1E-03,conv=1,fc=2\n",
      "Starting run for lr_1E-03,conv=2,fc=2\n",
      "Starting run for lr_1E-04,conv=1,fc=2\n",
      "Starting run for lr_1E-04,conv=2,fc=2\n",
      "Done training!\n",
      "Run `tensorboard --logdir=/tmp/mnist_tutorial/` to see the results.\n",
      "Running on mac? If you want to get rid of the dialogue asking to give network permissions to TensorBoard, you can provide this flag: --host=localhost\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2017 Google, Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "LOGDIR = \"/log/mnist_tutorial/\"\n",
    "LABELS = os.path.join(os.getcwd(), \"labels_1024.tsv\")\n",
    "SPRITES = os.path.join(os.getcwd(), \"sprite_1024.png\")\n",
    "### MNIST EMBEDDINGS ###\n",
    "mnist = tf.contrib.learn.datasets.mnist.read_data_sets(train_dir=LOGDIR + \"data\", one_hot=True)\n",
    "### Get a sprite and labels file for the embedding projector ###\n",
    "\n",
    "if not (os.path.isfile(LABELS) and os.path.isfile(SPRITES)):\n",
    "    print(\"Necessary data files were not found. Run this command from inside the \"\n",
    "    \"repo provided at \"\n",
    "    \"https://github.com/dandelionmane/tf-dev-summit-tensorboard-tutorial.\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# shutil.copyfile(LABELS, os.path.join(LOGDIR, LABELS))\n",
    "# shutil.copyfile(SPRITES, os.path.join(LOGDIR, SPRITES))\n",
    "\n",
    "\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "        return act\n",
    "\n",
    "\n",
    "def mnist_model(learning_rate, use_two_fc, use_two_conv, hparam):\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Setup placeholders, and reshape the data\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name=\"x\")\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input', x_image, 3)\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "    \n",
    "    if use_two_conv:\n",
    "        conv1 = conv_layer(x_image, 1, 32, \"conv1\")\n",
    "        conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "    else:\n",
    "        conv_out = conv_layer(x_image, 1, 16, \"conv\")\n",
    "\n",
    "    flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64])\n",
    "\n",
    "\n",
    "    if use_two_fc:\n",
    "        fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, \"fc1\")\n",
    "        relu = tf.nn.relu(fc1)\n",
    "        embedding_input = relu\n",
    "        tf.summary.histogram(\"fc1/relu\", relu)\n",
    "        embedding_size = 1024\n",
    "        logits = fc_layer(relu, 1024, 10, \"fc2\")\n",
    "    else:\n",
    "        embedding_input = flattened\n",
    "        embedding_size = 7*7*64\n",
    "        logits = fc_layer(flattened, 7*7*64, 10, \"fc\")\n",
    "\n",
    "    with tf.name_scope(\"xent\"):\n",
    "        xent = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"xent\")\n",
    "        tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "    with tf.name_scope(\"accuracy\"):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "    summ = tf.summary.merge_all()\n",
    "\n",
    "\n",
    "    embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"test_embedding\")\n",
    "    assignment = embedding.assign(embedding_input)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = embedding.name\n",
    "    embedding_config.sprite.image_path = SPRITES\n",
    "    embedding_config.metadata_path = LABELS\n",
    "    # Specify the width and height of a single thumbnail.\n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
    "\n",
    "    for i in range(2001):\n",
    "        batch = mnist.train.next_batch(100)\n",
    "        if i % 5 == 0:\n",
    "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], y: batch[1]})\n",
    "            writer.add_summary(s, i)\n",
    "        if i % 500 == 0:\n",
    "            sess.run(assignment, feed_dict={x: mnist.test.images[:1024], y: mnist.test.labels[:1024]})\n",
    "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y: batch[1]})\n",
    "\n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "    conv_param = \"conv=2\" if use_two_conv else \"conv=1\"\n",
    "    fc_param = \"fc=2\" if use_two_fc else \"fc=1\"\n",
    "    return \"lr_%.0E,%s,%s\" % (learning_rate, conv_param, fc_param)\n",
    "\n",
    "def main():\n",
    "    # You can try adding some more learning rates\n",
    "    for learning_rate in [1E-3, 1E-4]:\n",
    "        \n",
    "        # Include \"False\" as a value to try different model architectures\n",
    "        for use_two_fc in [True]:\n",
    "            for use_two_conv in [False, True]:\n",
    "                # Construct a hyperparameter string for each one (example: \"lr_1E-3,fc=2,conv=2\")\n",
    "                hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "                print('Starting run for %s' % hparam)\n",
    "\n",
    "                # Actually run with the new settings\n",
    "                mnist_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "    print('Done training!')\n",
    "    print('Run `tensorboard --logdir=%s` to see the results.' % LOGDIR)\n",
    "    print('Running on mac? If you want to get rid of the dialogue asking to give '\n",
    "        'network permissions to TensorBoard, you can provide this flag: '\n",
    "        '--host=localhost')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"10\"  style=\"height:43px\">\n",
    "<div style=\"position:absolute;width:40%;height:28px;border: 4px solid black;background-color:black;color:white;text-align:center;border-radius:0px 0px 0px 0px;padding:3px;box-shadow: 0 4px 8px 0 grey, 0 6px 20px 0 rgba(0, 0, 0, 0.19);border-radius:5px 5px 5px 5px;\">\n",
    "    <h5>  Hyperparameter Search: </h5>\n",
    "</div>\n",
    "   \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a few learning rate:\n",
    "for learning_rate in [1e-3, 1e-4, 1e-5]:\n",
    "    # try a model with fewer layers:\n",
    "    for use_two_fc in [True, False]:\n",
    "        for use_two_conv in [True, False]:\n",
    "            # construct a hyparamter string for each one (example: lr=1e-4, fc=2, conv=2)\n",
    "            hparam_str = make_hparam_string(learning_rate, use_two_fc, use_two_conv )\n",
    "            \n",
    "            writer = tf.summary.FileWriter('/tmp/minist_tutorial/'+hparam_str)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
