{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"card rounded bg-primary text-center\" style=\"width:100%;\">\n",
    "\n",
    "<header class=\"card-title center\" style=\"width:100%;height:140px;\">\n",
    "  <h1>Chapter 2.3</h1>\n",
    "    <h1><b>+ PLus Theory 2</b></h1>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\" color=\"#721800\"><b>  inforamtion Theory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## underflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "underflow occures when numbers near zeros are rounded zero are rounded to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overflow occures when numbers with large magnitude are approximated as ∞ or -∞ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note:</b> <font color=\"red\">Softmax funcation</font> is one of a funcation that must be stabilized against underflow and overflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poor condution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conditioning refers to how rapidly a funcation change respect to small changes in its inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Based Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the funcation we want to minimize or maximize is called the <b>objective funcation</b> or <b>critertion</b>\n",
    "- when we are minimizing it, call it cost fucation, loss fucation or error funcation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jscobian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negtive Curative, No curative, Postive Curative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Negtive Curative:</b> cost funcation will actually decreses by more than e.<br>\n",
    "<b>No Curative:</b> Then it isn't curative. it is perfectly flat line, anf it is value can be perdicated using only gradiet.<br>\n",
    "<b>Negtive Curative:</b>cost funcation will actually decreses by less than e.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"12\" color=\"#721800\"><b> Chapter 5 of book - Machine Learning Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\" Machine learning is a computer program is saied to learn from exprince E with respect to some class of tasks T and perforamnce  measure P. if its perforamnce at task in T, as measured by P, improves with exprince E\" <b>Mitchell (1997)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is a specific kind of machine learning. <br>\n",
    "most Deep learning used a based aslgorithms on an optimizer algorithm called <b>Stochastic gradient descent</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1 . Liner regression]()\n",
    "[2. ferquentist estimators ]()\n",
    "[2. Bayesian inference]()\n",
    "[2. ]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Classfication ,\n",
    "2. Classfication with missing inputs,\n",
    "3. Regression,\n",
    "4. Transcription,\n",
    "5. Machine translation,\n",
    "6. structured output,\n",
    "7. Anomaly detection,\n",
    "8. Sythesis and sampling,\n",
    "9. Imputation of missing values,\n",
    "10. Denoising,\n",
    "11. Density estimation or probility mass fucation estimation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different kind of machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Superviser Learning\n",
    "2. Unsuerviser Learning,\n",
    "3. Reinforsement,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Liner regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model takes a vectors x (is R^n) as input and perdict the values of scalar y (is R) as its output. The output of linear regression is a linear funcation of the input.<br>\n",
    "y = (w^T)x  <br>\n",
    "w (is R^n) is a vector of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## capacity, overfitting and underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How understainding a machien learning works perfect?</b><br>\n",
    "1. Make the training error small.\n",
    "2. Make the gap between training error and test error (generalization error) small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Underfitting </b>occurs when the model is not able to obtain a sufficiently low error value on the training set.<br>\n",
    "<b>Overfitting </b>occures when the gap between the training error and test error is too large.<br>\n",
    "(we can cotrol wether a model is more likely to overfit or underfit by altering its <b>capacity</b>.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes error:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set:\n",
    "used to estimate the generalization error during or after training, allowing hyperparameters to br ubdated accordingly.<br>\n",
    "Typically, one uses about 80 percent of the training data for training and 20 percent for validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
